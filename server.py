import os
import io
import cv2
import torch
import numpy as np
import gc
import logging
from PIL import Image
from ultralytics import YOLO, SAM
from fastapi import FastAPI, File, UploadFile, Response
from fastapi.middleware.cors import CORSMiddleware
import psutil

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸŒŸ ì„¤ì •ê°’
YOLO_CONF_THRESHOLD = 0.001
MIN_BOX_RATIO = 0.003
MORPHOLOGY_KERNEL_SIZE = 11
GAUSSIAN_BLUR_SIZE = 21
DEPTH_DIFF_THRESHOLD = 8
TOP_BOTTOM_REMOVE_RATIO = 0.15
MAX_IMAGE_SIZE_PIXELS = 640

# ğŸ“Œ ì „ì—­ ëª¨ë¸
det_model = None
sam_model = None
device = "cpu"


# â­ ëª¨ë¸ ë¡œë“œ (ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•´ YOLOv8n ê¶Œì¥)
@app.on_event("startup")
def load_models_on_startup():
    global det_model, sam_model, device
    logger.info("[ğŸ”¥] Loading Models...")
    device = "cpu"

    # ğŸš¨ ë©”ëª¨ë¦¬ ì•ˆì •ì„± í™•ë³´ë¥¼ ìœ„í•´ YOLOv8n.pt ì‚¬ìš©ì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤.
    YOLO_MODEL_NAME = "yolov8n.pt" 
    SAM_MODEL_NAME = "mobile_sam.pt"

    try:
        if os.path.exists(YOLO_MODEL_NAME):
            det_model = YOLO(YOLO_MODEL_NAME)
            det_model.to(device)
            logger.info(f"[âœ”ï¸] {YOLO_MODEL_NAME} Loaded")
        else:
            logger.error(f"[âŒ] {YOLO_MODEL_NAME} Not Found")

        if os.path.exists(SAM_MODEL_NAME):
            sam_model = SAM(SAM_MODEL_NAME)
            sam_model.to(device)
            logger.info(f"[âœ”ï¸] {SAM_MODEL_NAME} Loaded")
        else:
            logger.error(f"[âŒ] {SAM_MODEL_NAME} Not Found")

    except Exception as e:
        logger.error(f"[ğŸ’¥] Model Load Error: {e}")


# ğŸ§° ì´ë¯¸ì§€ ë¡œë“œ
def pil_from_bytes(file_bytes: bytes, mode="RGB") -> Image.Image:
    try:
        # ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ë•Œ, ë¦¬ì‚¬ì´ì§• ë¡œì§ì„ ì¶”ê°€í•˜ì—¬ ë©”ëª¨ë¦¬ ì´ˆê³¼ ë°©ì§€
        img = Image.open(io.BytesIO(file_bytes)).convert(mode)
        w, h = img.size
        
        if max(w, h) > MAX_IMAGE_SIZE_PIXELS:
            ratio = MAX_IMAGE_SIZE_PIXELS / max(w, h)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.LANCZOS)
            logger.warning(f"[âš ï¸] ì´ë¯¸ì§€ í¬ê¸°ë¥¼ {w}x{h}ì—ì„œ {new_size[0]}x{new_size[1]}ë¡œ ì¶•ì†Œí–ˆìŠµë‹ˆë‹¤.")
            
        return img

    except Exception as e:
        logger.error(f"Image Load Error: {e}")
        return None

# (ë‚˜ë¨¸ì§€ í•„í„°ë§ í•¨ìˆ˜ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€)
# ğŸ§± ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬
def post_refine(mask: np.ndarray):
    mask = mask.astype(np.uint8)
    kernel = np.ones((MORPHOLOGY_KERNEL_SIZE, MORPHOLOGY_KERNEL_SIZE), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    mask = cv2.dilate(mask, kernel, iterations=1)

    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        return mask

    largest = max(cnts, key=cv2.contourArea)
    clean = np.zeros_like(mask)
    cv2.drawContours(clean, [largest], -1, 1, thickness=cv2.FILLED)
    clean = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel, iterations=2)
    return clean


# ğŸª“ ì²œì¥ + ë°”ë‹¥ ì œê±°
def remove_top_bottom(mask, ratio=TOP_BOTTOM_REMOVE_RATIO):
    h = mask.shape[0]
    cut = int(h * ratio)
    mask[:cut, :] = 0
    mask[h-cut:, :] = 0
    return mask


# ğŸ§± ìˆ˜ì§ë©´(ë²½)ë§Œ ë‚¨ê¸°ê¸°
def filter_vertical_surfaces(depth_map, threshold=DEPTH_DIFF_THRESHOLD):
    depth_map = depth_map.astype(np.float32)
    dx = cv2.Sobel(depth_map, cv2.CV_32F, 1, 0, ksize=3)
    dy = cv2.Sobel(depth_map, cv2.CV_32F, 0, 1, ksize=3)
    magnitude = cv2.magnitude(dx, dy)
    
    # ìˆ˜í‰ ê¸°ìš¸ê¸°ê°€ ìˆ˜ì§ ê¸°ìš¸ê¸°ë³´ë‹¤ ì•½í•  ë•Œ (ì¦‰, í‰í‰í•œ ìˆ˜ì§ë©´ì¼ ê°€ëŠ¥ì„±)ë¥¼ ë²½ìœ¼ë¡œ ê°€ì •.
    # ì´ ë¡œì§ì€ ê¹Šì´ ë§µì´ ë§¤ìš° ê¹¨ë—í•˜ì§€ ì•Šìœ¼ë©´ ë…¸ì´ì¦ˆê°€ ì‹¬í•  ìˆ˜ ìˆìŒ.
    vertical_strong_mask = (magnitude < threshold * 2).astype(np.uint8) # í° ê¹Šì´ ë³€í™”ëŠ” ê°ì²´ë¡œ ê°„ì£¼
    
    # ê¹Šì´ ë§µì˜ ë…¸ì´ì¦ˆê°€ ì‹¬í•  ê²½ìš° ì´ í•„í„°ëŠ” ìµœì¢… ê²°ê³¼ì— ì•…ì˜í–¥ì„ ì¤Œ
    return vertical_strong_mask


# ğŸ›‘ ì „ê²½ ê°ì²´ ì œê±° (Sobel ê¸°ë°˜)
def create_depth_occlusion_mask(depth_map: np.ndarray, threshold=DEPTH_DIFF_THRESHOLD) -> np.ndarray:
    if depth_map is None:
        return None
    depth_map = depth_map.astype(np.float32)
    grad_x = cv2.Sobel(depth_map, cv2.CV_32F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(depth_map, cv2.CV_32F, 0, 1, ksize=3)
    magnitude = cv2.magnitude(grad_x, grad_y)
    # ê¹Šì´ ì°¨ì´ê°€ ì„ê³„ê°’ ì´ìƒì¸ ê³³ì„ ê°ì²´ì˜ ê²½ê³„(Occlusion)ë¡œ ê°„ì£¼
    occl = (magnitude > threshold).astype(np.uint8)
    kernel = np.ones((5, 5), np.uint8)
    return cv2.dilate(occl, kernel, iterations=2)


# ğŸšª Wall Mask API
@app.post("/segment_wall_mask")
async def generate_mask(
        image: UploadFile = File(...),
        depth: UploadFile = File(...)
):
    global det_model, sam_model

    if det_model is None or sam_model is None:
        logger.error("Models not loaded.")
        return Response(content="Model load failed. Check server startup logs.", status_code=503)
    
    # ğŸ“Œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
    # ì´ í•¨ìˆ˜ì—ì„œ ë¦¬ì‚¬ì´ì§•ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    img_pil = pil_from_bytes(await image.read())
    # ê¹Šì´ ë§µë„ ë™ì¼í•œ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì§• ë° í‘ë°± ë³€í™˜
    depth_bytes = await depth.read()
    depth_pil = pil_from_bytes(depth_bytes, mode="L")
    
    if img_pil is None or depth_pil is None:
        return Response(content="Invalid Image or Depth File.", status_code=400)

    img = np.array(img_pil)
    depth_map = np.array(depth_pil)
    h, w, _ = img.shape
    
    # ğŸ§± YOLO ê°ì§€ (ëª¨ë“  ê°ì²´ bbox)
    logger.info("[ğŸ”] YOLOv8n: ê°ì²´ ê°ì§€ ì¤‘...")
    det = det_model(img, conf=YOLO_CONF_THRESHOLD, device=device, verbose=False)[0]
    boxes = det.boxes.xyxy.cpu().numpy() if det.boxes is not None else []
    
    del det
    gc.collect()

    if len(boxes) == 0:
        logger.warning("[âš ï¸] ê°ì²´ ë°•ìŠ¤ê°€ ì—†ì–´ ì „ì²´ í™”ë©´(ë²½) ë§ˆìŠ¤í¬ ë°˜í™˜.")
        final_mask = np.ones((h, w), dtype=np.uint8)
    else:
        # ğŸ¯ MobileSAM predict (ëª¨ë“  ê°ì²´ ë¶„í• í•˜ì—¬ í•©ì§‘í•© ê³„ì‚°)
        logger.info(f"[ğŸ¨] MobileSAM: {len(boxes)}ê°œ ê°ì²´ ë¶„í•  ì¤‘...")
        sam_results = sam_model.predict(img, bboxes=boxes, device=device, verbose=False)[0]

        if sam_results.masks is None or sam_results.masks.data is None:
            logger.warning("[âš ï¸] MobileSAM ë¶„í•  ì‹¤íŒ¨. ì „ì²´ í™”ë©´(ë²½) ë§ˆìŠ¤í¬ ë°˜í™˜.")
            final_mask = np.ones((h, w), dtype=np.uint8)
        else:
            # ëª¨ë“  ê°ì²´ ë§ˆìŠ¤í¬ì˜ í•©ì§‘í•© (Union) ê³„ì‚°
            mask_data = sam_results.masks.data.cpu().numpy()
            union_objects_mask = (mask_data.sum(axis=0) > 0).astype(np.uint8)
            del mask_data, sam_results
            
            # ë²½ ë§ˆìŠ¤í¬ = 1 - ê°ì²´ í•©ì§‘í•© ë§ˆìŠ¤í¬
            initial_wall_mask = 1 - union_objects_mask
            
            # ğŸ§¼ í›„ì²˜ë¦¬
            initial_wall_mask = post_refine(initial_wall_mask)
            
            final_mask = initial_wall_mask
            del initial_wall_mask

    # ----------------------------------------------------
    # ğŸ”¨ ê¹Šì´ ë° ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§ (ë””ë²„ê¹…ì„ ìœ„í•´ ì£¼ì„ í•´ì œí•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”)
    # ----------------------------------------------------
    
    # 1. ğŸ›‘ ê¹Šì´ ê¸°ë°˜ ì „ê²½ ê°ì²´ ì œê±° (occlusion)
    occl = create_depth_occlusion_mask(depth_map)
    if occl is not None:
        # final_mask *= (1 - occl) 
        pass # í˜„ì¬ëŠ” ì£¼ì„ ì²˜ë¦¬í•˜ì—¬ ì•ˆì •ì„± ìš°ì„ 

    # 2. ğŸª“ ì²œì¥/ë°”ë‹¥ ì œê±°
    # final_mask = remove_top_bottom(final_mask)
    
    # 3. ğŸ¯ ìˆ˜ì§ ë²½ë§Œ ìœ ì§€ (ê°€ì¥ ê°•ë ¥í•œ í•„í„°)
    # vertical_surface_mask = filter_vertical_surfaces(depth_map)
    # final_mask *= vertical_surface_mask
    
    # ----------------------------------------------------
    
    # ğŸ’§ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ
    final_mask = cv2.GaussianBlur(final_mask.astype(np.float32), (GAUSSIAN_BLUR_SIZE, GAUSSIAN_BLUR_SIZE), 0)

    # ğŸ PNG ë°˜í™˜
    _, png = cv2.imencode(".png", (final_mask * 255).astype(np.uint8))
    
    gc.collect()
    
    return Response(png.tobytes(), media_type="image/png")


# ì„œë²„ ìƒíƒœ
@app.get("/")
async def root():
    return {"status": "ok", "message": "Wall Detection Server Ready"}


@app.get("/health")
async def health():
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    gc.collect()
    return {
        "status": "healthy",
        "models_loaded": det_model is not None and sam_model is not None,
        "memory_mb": round(memory_mb, 2)
    }