import os
import io
import cv2
import torch
import numpy as np
import gc
import logging
from PIL import Image
from ultralytics import YOLO, SAM
from fastapi import FastAPI, File, UploadFile, Response, Form
from fastapi.middleware.cors import CORSMiddleware
import torch.hub
import psutil # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì ì„ ìœ„í•´ ì¶”ê°€

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==============================================================================
# ğŸ’¡ [ì¡°ì • ê°€ëŠ¥í•œ ì„¤ì •] - Wall/Object Estimation Parameters
# ==============================================================================
# 1. YOLOv8 ê°ì²´ ê°ì§€ ë¯¼ê°ë„: ë‚®ì¶œìˆ˜ë¡ ë” ë§ì€ ê°ì²´ë¥¼ ê°ì§€í•˜ì—¬ ë²½ ì˜ì—­ì—ì„œ ì œì™¸ 
YOLO_CONF_THRESHOLD = 0.01 
# 2. ë„ˆë¬´ ì‘ì€ ê°ì²´ ë°•ìŠ¤ í•„í„°ë§ ê¸°ì¤€: ë‚®ì¶œìˆ˜ë¡ ì‘ì€ ê°ì²´ê¹Œì§€ í¬í•¨í•˜ì—¬ ì œì™¸
MIN_BOX_RATIO = 0.005
# 3. ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì‹œ ì‚¬ìš©í•  ëª¨í´ë¡œì§€ ì»¤ë„ í¬ê¸°: í´ìˆ˜ë¡ ì •ì œ íš¨ê³¼ê°€ ê°•í•¨
MORPHOLOGY_KERNEL_SIZE = 9
# 4. ìµœì¢… ë§ˆìŠ¤í¬ ê²½ê³„ì˜ Gaussian Blur í¬ê¸°: í´ìˆ˜ë¡ ê²½ê³„ê°€ ë” ë¶€ë“œëŸ¬ì›€ 
GAUSSIAN_BLUR_SIZE = 13
# 5. ê¹Šì´ ë§µ ê¸°ë°˜ ê°ì²´ ì œê±° ë¯¼ê°ë„: ì´ ê°’ë³´ë‹¤ ê¹Šì´ ì°¨ì´ê°€ í¬ë©´ ê°ì²´ë¡œ ê°„ì£¼ (ë‚®ì¶œìˆ˜ë¡ ë¯¼ê°)
DEPTH_DIFF_THRESHOLD = 10 

# ì „ì—­ ë³€ìˆ˜
det_model = None  # YOLOv8s
sam_model = None  # MobileSAM
midas_model = None # MiDaS for Monocular Depth Estimation
device = "cpu"

# MiDaS DPT_Hybrid_Small ëª¨ë¸ì˜ í‘œì¤€ ì „ì²˜ë¦¬ ê°’ (MiDaS v2.1 Smallê³¼ ë™ì¼)
MIDAS_MEAN = torch.tensor([0.5, 0.5, 0.5]).float()
MIDAS_STD = torch.tensor([0.5, 0.5, 0.5]).float()

@app.on_event("startup")
def load_models_on_startup():
    """ì„œë²„ ì‹œì‘ ì‹œ YOLOv8s + MobileSAM + MiDaS ë¡œë“œ"""
    global det_model, sam_model, midas_model, device
    
    logger.info("[ğŸ”¥] Starting model loading for YOLOv8s + MobileSAM + MiDaS...")
    
    # CPU í™˜ê²½ ì„¤ì •
    device = "cpu"
    logger.info(f"[âš™ï¸] Device: {device}")
    
    yolo_checkpoint_path = "yolov8s.pt"
    sam_checkpoint_path = "mobile_sam.pt"

    try:
        # 1. YOLOv8s ëª¨ë¸ ë¡œë“œ
        if not os.path.exists(yolo_checkpoint_path):
             logger.error(f"[âŒ] YOLOv8s checkpoint not found at: {yolo_checkpoint_path}")
        else:
            det_model = YOLO(yolo_checkpoint_path)
            det_model.to(device)
            logger.info("[âœ…] YOLOv8s loaded.")
        
        # 2. MobileSAM ë¡œë“œ
        if not os.path.exists(sam_checkpoint_path):
             logger.error(f"[âŒ] MobileSAM checkpoint not found at: {sam_checkpoint_path}")
        else:
            sam_model = SAM(sam_checkpoint_path)
            sam_model.to(device)
            logger.info("[âœ…] MobileSAM loaded.")
            
        # 3. MiDaS ëª¨ë¸ ë¡œë“œ (ìµœì†Œí˜• ëª¨ë¸ DPT_Hybrid_Smallë¡œ ë³€ê²½)
        midas_type = "DPT_Hybrid_Small" 
        midas_model = torch.hub.load("intel-isl/MiDaS", midas_type, trust_repo=True, map_location=device)
        midas_model.to(device)
        midas_model.eval()
        
        logger.info(f"[âœ…] MiDaS ({midas_type}) loaded on CPU. (ìµœì†Œ ë©”ëª¨ë¦¬ ëª¨ë¸)")

    except Exception as e:
        logger.error(f"[âŒ] FATAL Model loading failed: {e}", exc_info=True)
        midas_model = None


def np_from_upload(file_bytes: bytes, mode="RGB") -> Image.Image:
    """ë°”ì´íŠ¸ë¥¼ PIL Imageë¡œ ë³€í™˜"""
    try:
        return Image.open(io.BytesIO(file_bytes)).convert(mode)
    except Exception as e:
        logger.error(f"Failed to open image from bytes: {e}")
        return None

# ==============================================================================
# --- MiDaS ê¹Šì´ ë§µ ìƒì„± í•¨ìˆ˜ ---
# ==============================================================================
def generate_depth_map_midas(pil_img: Image.Image, output_size: tuple) -> np.ndarray:
    """
    MiDaS ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ RGB ì´ë¯¸ì§€ë¡œë¶€í„° ê¹Šì´ ë§µì„ ì¶”ì •í•©ë‹ˆë‹¤.
    [ìˆ˜ë™ ì „ì²˜ë¦¬]: ì˜¤ë¥˜ë¥¼ íšŒí”¼í•˜ê¸° ìœ„í•´ transform ëŒ€ì‹  ìˆ˜ë™ìœ¼ë¡œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    if midas_model is None:
        logger.error("MiDaS model not initialized.")
        return None

    try:
        # 1. NumPy ë°°ì—´ë¡œ ë³€í™˜ ë° ì •ê·œí™”
        img_np = np.array(pil_img) # H, W, 3 (uint8)
        img_float = img_np.astype(np.float32) / 255.0 # H, W, 3 (float 0-1)
        
        # 2. PyTorch í…ì„œë¡œ ë³€í™˜ ë° ì°¨ì› ë³€ê²½ (H, W, C -> C, H, W)
        tensor = torch.from_numpy(img_float).permute(2, 0, 1) # 3, H, W
        
        # 3. MiDaS í‘œì¤€ ì •ê·œí™” ì ìš© (Mean and Std)
        for i in range(3):
            tensor[i].sub_(MIDAS_MEAN[i]).div_(MIDAS_STD[i])

        
        # 4. ë°°ì¹˜ ì°¨ì› ì¶”ê°€ ë° ë””ë°”ì´ìŠ¤ ì´ë™
        input_batch = tensor.unsqueeze(0).to(device) # 1, 3, H, W
        del tensor # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ
        
        with torch.no_grad():
            # 5. MiDaS ëª¨ë¸ ì‹¤í–‰
            prediction = midas_model(input_batch)
            del input_batch # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ
            
            # 6. ì¶œë ¥ í¬ê¸°ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
            prediction = torch.nn.functional.interpolate(
                prediction.unsqueeze(1),
                size=pil_img.size[::-1], # (H, W)
                mode="bicubic",
                align_corners=False,
            ).squeeze()
        
        # 7. NumPyë¡œ ë³€í™˜ ë° ì •ê·œí™”
        depth_map = prediction.cpu().numpy()
        del prediction # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ
        
        # 8. ê¹Šì´ ë§µì„ 0-255 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”
        depth_min = depth_map.min()
        depth_max = depth_map.max()
        depth_range = depth_max - depth_min
        
        if depth_range > 0:
            normalized_depth = (depth_map - depth_min) / depth_range
        else:
            normalized_depth = np.zeros_like(depth_map, dtype=np.float32)

        # 0-255 ë²”ìœ„ì˜ 8ë¹„íŠ¸ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        normalized_depth_uint8 = (normalized_depth * 255).astype(np.uint8)
        
        logger.info("[âœ…] MiDaS (DPT_Hybrid_Small) ê¹Šì´ ë§µ ìƒì„± ì™„ë£Œ.")
        return normalized_depth_uint8

    except Exception as e:
        logger.error(f"MiDaS depth generation failed: {e}", exc_info=True)
        return None


def filter_small_boxes(boxes, img_shape, min_ratio=MIN_BOX_RATIO):
    """ë„ˆë¬´ ì‘ì€ ë°•ìŠ¤ í•„í„°ë§ (ë…¸ì´ì¦ˆ ì œê±°)."""
    H, W = img_shape
    area_img = H * W
    filtered = []
    for x1, y1, x2, y2 in boxes:
        area = (x2 - x1) * (y2 - y1)
        # ë©´ì ì´ ì „ì²´ ì´ë¯¸ì§€ì˜ min_ratio ë¯¸ë§Œì´ë©´ í•„í„°ë§
        if area / area_img > min_ratio:
            filtered.append([float(x1), float(y1), float(x2), float(y2)])
    return filtered


def post_refine(mask: np.ndarray):
    """ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬: ë…¸ì´ì¦ˆ ì œê±°, í™•ëŒ€, ê°€ì¥ í° ì—°ê²° ì˜ì—­ë§Œ ë‚¨ê¸°ê¸° (ë²½ ì˜ì—­ ì¶”ì •)."""
    mask = mask.astype(np.uint8)
    kernel = np.ones((MORPHOLOGY_KERNEL_SIZE, MORPHOLOGY_KERNEL_SIZE), np.uint8)

    # ë…¸ì´ì¦ˆ ì œê±° (Opening) + ê²½ê³„ ì±„ìš°ê¸° (Dilate)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    mask = cv2.dilate(mask, kernel, iterations=1)

    # ê°€ì¥ í° ì—°ê²° ì˜ì—­ë§Œ ë‚¨ê¸°ê¸°
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        return mask

    largest = max(cnts, key=cv2.contourArea)
    clean = np.zeros_like(mask)
    cv2.drawContours(clean, [largest], -1, 1, thickness=cv2.FILLED)
    
    # ì˜ì—­ì„ ë¶€ë“œëŸ½ê²Œ ë‹«ê¸° (Closing)
    clean = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel, iterations=2)
    return clean


def create_depth_occlusion_mask(depth_map: np.ndarray, threshold=DEPTH_DIFF_THRESHOLD) -> np.ndarray:
    """
    ê¹Šì´ ì§€ë„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ê²½ ê°ì²´(Occlusion) ë§ˆìŠ¤í¬ ìƒì„±.
    ì¸ì ‘ í”½ì…€ ê°„ì˜ ê¸‰ê²©í•œ ê¹Šì´ ë³€í™”(ê²½ê³„)ë¥¼ ì°¾ì•„ ê°ì²´ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    """
    if depth_map is None:
        return None
        
    depth_map = depth_map.astype(np.float32)
    
    # Sobel í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¹Šì´ ë§µì˜ ê²½ê³„(ê¹Šì´ ë³€í™”ê°€ í° ë¶€ë¶„)ë¥¼ ê²€ì¶œ
    grad_x = cv2.Sobel(depth_map, cv2.CV_32F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(depth_map, cv2.CV_32F, 0, 1, ksize=3)
    
    # ê²½ê³„ ê°•ë„ ê³„ì‚° (Magnitude)
    magnitude = cv2.magnitude(grad_x, grad_y)
    del grad_x, grad_y # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ
    
    # ì„ê³„ê°’ ì´ìƒì˜ ê²½ê³„ë§Œ ë§ˆìŠ¤í‚¹ (ê°ì²´ = 1, ë°°ê²½ = 0)
    occlusion_mask = (magnitude > threshold).astype(np.uint8)
    del magnitude # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ
    
    # ë§ˆìŠ¤í¬ í™•ì¥ (dilate)í•˜ì—¬ ê°ì²´ ì˜ì—­ì„ í™•ì‹¤í•˜ê²Œ ë®ìŠµë‹ˆë‹¤.
    kernel = np.ones((5, 5), np.uint8)
    occlusion_mask = cv2.dilate(occlusion_mask, kernel, iterations=2)
    
    return occlusion_mask


@app.get("/")
async def root():
    return {"status": "ok", "message": "YOLOv8s + MobileSAM + DPT_Hybrid_Small Integrated Server"}


@app.get("/health")
async def health():
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    
    gc.collect()
    
    return {
        "status": "healthy",
        "models_loaded": det_model is not None and sam_model is not None and midas_model is not None,
        "device": device,
        "memory_mb": round(memory_mb, 2)
    }


@app.post("/segment_wall_mask")
async def segment_wall_mask(
    rgb_file: UploadFile = File(..., alias="rgb_file"), # ìœ ë‹ˆí‹° ì¹´ë©”ë¼ ì´ë¯¸ì§€
    depth_file: UploadFile = File(..., alias="depth_file") # ìœ ë‹ˆí‹° ê¹Šì´ ì§€ë„ (í‘ë°± PNG ê°€ì •)
):
    """YOLOv8s+SAMìœ¼ë¡œ ê°ì²´ ê°ì§€/ë¶„í•  í›„, MiDaS ë˜ëŠ” ì‹¤ì œ ê¹Šì´ ì§€ë„ë¡œ ìµœì¢… ê°€ë ¤ì§ ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•˜ì—¬ ë²½ ì˜ì—­ ì¶”ì¶œ"""
    
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024
    logger.info(f"[ğŸ§ ] ìš”ì²­ ì‹œì‘ ë©”ëª¨ë¦¬: {initial_memory:.2f} MB")
    
    # ëª¨ë¸ ë¡œë”© ì—¬ë¶€ í™•ì¸
    if det_model is None or sam_model is None or midas_model is None:
        logger.error("Segmentation services are unavailable due to model loading failure or MiDaS initialization failure.")
        return Response(content="Model load failed. Check server startup logs.", status_code=503)

    pil_img = depth_img_np = depth_occlusion_mask = None 

    try:
        # 1. RGB ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        rgb_bytes = await rgb_file.read()
        pil_img = np_from_upload(rgb_bytes, mode="RGB")
        del rgb_bytes # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ
        
        if pil_img is None:
            logger.error("RGB file could not be loaded.")
            return Response(content="Invalid RGB image file.", status_code=400)
            
        original_size = pil_img.size
        
        max_size = 640
        if max(pil_img.size) > max_size:
            ratio = max_size / max(pil_img.size)
            new_size = tuple(int(dim * ratio) for dim in pil_img.size)
            # PIL Image.resizeëŠ” ìƒˆ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ì´ì „ pil_imgëŠ” GC ëŒ€ìƒì´ ë¨
            pil_img = pil_img.resize(new_size, Image.LANCZOS) 

        w, h = pil_img.size
        logger.info(f"[ğŸ“¸] RGB ì´ë¯¸ì§€: {w}x{h}")
        
        # 2. ê¹Šì´ ì§€ë„ ë¡œë“œ ë° MiDaS í´ë°± ì ìš©
        depth_bytes = await depth_file.read()
        
        # í´ë¼ì´ì–¸íŠ¸ ê¹Šì´ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if depth_bytes and len(depth_bytes) > 100: 
            depth_img = np_from_upload(depth_bytes, mode="L")
            if depth_img is not None:
                depth_img_np = np.array(depth_img.resize((w, h), Image.NEAREST))
                del depth_img
                logger.info("[âœ…] í´ë¼ì´ì–¸íŠ¸ ê¹Šì´ ì§€ë„ ë¡œë“œ ì™„ë£Œ.")
            else:
                logger.warning("[âš ï¸] í´ë¼ì´ì–¸íŠ¸ ê¹Šì´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. MiDaSë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                depth_img_np = generate_depth_map_midas(pil_img, (w, h))
        else:
            logger.warning("[âš ï¸] í´ë¼ì´ì–¸íŠ¸ ê¹Šì´ íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. MiDaSë¡œ ê¹Šì´ ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.")
            depth_img_np = generate_depth_map_midas(pil_img, (w, h))
        
        del depth_bytes # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ

        # 3. YOLOv8s + MobileSAMìœ¼ë¡œ ì´ˆê¸° ë²½ ë§ˆìŠ¤í¬ ìƒì„±
        logger.info("[ğŸ”] YOLOv8s: ê°ì²´ ê°ì§€ ì¤‘...")
        results = det_model.predict(
            pil_img, conf=YOLO_CONF_THRESHOLD, imgsz=640, device=device, verbose=False,
        )[0]
        
        xyxy = results.boxes.xyxy.cpu().numpy() if results.boxes is not None else []
        del results # ğŸš¨ YOLO ê²°ê³¼ ê°ì²´ ì¦‰ì‹œ ë©”ëª¨ë¦¬ í•´ì œ
        
        boxes = filter_small_boxes(xyxy, pil_img.size[::-1])
        del xyxy
        logger.info(f"[âœ…] {len(boxes)}ê°œì˜ ìœ íš¨ ê°ì²´ ë°•ìŠ¤ ë°œê²¬")

        if not boxes:
            logger.warning("[âš ï¸] ê°ì²´ ë°•ìŠ¤ê°€ ì—†ì–´ ì „ì²´ ì´ë¯¸ì§€(ë²½) ë°•ìŠ¤ ì‚¬ìš©.")
            initial_wall_mask = np.ones((h, w), dtype=np.uint8) * 255
        else:
            logger.info("[ğŸ¨] MobileSAM: ê°ì²´ ë¶„í•  ì¤‘...")
            res = sam_model.predict(
                pil_img, bboxes=boxes, device=device, retina_masks=False, verbose=False
            )[0]
            del boxes # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ
            
            if res.masks is None:
                logger.warning("[âš ï¸] MobileSAM ë¶„í•  ì‹¤íŒ¨. ì „ì²´ í™”ë©´ ë°˜í™˜.")
                initial_wall_mask = np.ones((h, w), dtype=np.uint8) * 255
                del res
            else:
                # ë§ˆìŠ¤í¬ í†µí•© ë° ë°˜ì „ (ë²½ ì˜ì—­ ì¶”ì¶œ)
                mask_data = res.masks.data.cpu().numpy()
                del res # ğŸš¨ SAM ê²°ê³¼ ê°ì²´ ì¦‰ì‹œ ë©”ëª¨ë¦¬ í•´ì œ
                
                union_objects = (mask_data.sum(axis=0) > 0).astype(np.uint8)
                del mask_data
                
                background_mask = 1 - union_objects # ê°ì²´ ë§ˆìŠ¤í¬ ë°˜ì „
                del union_objects
                
                # í›„ì²˜ë¦¬ (ê°€ì¥ í° ë°°ê²½ ì˜ì—­ë§Œ ë‚¨ê¹€)
                refined_background = post_refine(background_mask) 
                del background_mask
                
                initial_wall_mask = (refined_background * 255).astype(np.uint8)
                del refined_background


        # 4. ê¹Šì´ ì§€ë„ë¥¼ ì´ìš©í•œ ìµœì¢… ê°ì²´ ì œì™¸ ë§ˆìŠ¤í‚¹ (Depth Occlusion)
        final_mask_img = initial_wall_mask.copy()
        del initial_wall_mask
        
        if depth_img_np is not None:
            depth_occlusion_mask = create_depth_occlusion_mask(depth_img_np)
            del depth_img_np # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ
            
            if depth_occlusion_mask is not None:
                # ê¹Šì´ ë§ˆìŠ¤í¬ë¥¼ ë°˜ì „í•˜ì—¬ ë²½ ë§ˆìŠ¤í¬(ë²½=1, ê°ì²´=0)ë¥¼ ì–»ê³  ê¸°ì¡´ ë§ˆìŠ¤í¬ì™€ AND ì—°ì‚°
                wall_from_depth = 1 - depth_occlusion_mask 
                del depth_occlusion_mask
                
                # 2D AI ë§ˆìŠ¤í¬ì™€ 3D ê¹Šì´ ë§ˆìŠ¤í¬ë¥¼ ê²°í•©
                combined_mask = cv2.bitwise_and(final_mask_img, wall_from_depth * 255)
                final_mask_img = combined_mask
                del wall_from_depth, combined_mask
                
                logger.info("[âœ…] ê¹Šì´ ë°ì´í„°(í´ë¼ì´ì–¸íŠ¸ or MiDaS)ë¡œ ìµœì¢… ê°€ë ¤ì§ ë³´ì • ì™„ë£Œ.")
            else:
                logger.warning("[âš ï¸] ê¹Šì´ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨. 2D AI ë§ˆìŠ¤í¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            logger.warning("[âš ï¸] ê¹Šì´ ë°ì´í„°ê°€ ì—†ì–´ 2D AI ë§ˆìŠ¤í¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # 5. ìµœì¢… ë§ˆìŠ¤í¬ ì •ë¦¬ ë° ì¸ì½”ë”©
        
        # ê²½ê³„ë©´ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬ (Smoothing)
        final_mask_img = cv2.GaussianBlur(final_mask_img, (GAUSSIAN_BLUR_SIZE, GAUSSIAN_BLUR_SIZE), 0)
        
        # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
        if pil_img.size != original_size:
            final_mask_img = cv2.resize(
                final_mask_img, 
                original_size, 
                interpolation=cv2.INTER_LINEAR
            )
        
        del pil_img
        
        # PNG ì¸ì½”ë”©
        _, png = cv2.imencode(".png", final_mask_img)
        del final_mask_img, _ # ğŸš¨ ë©”ëª¨ë¦¬ í•´ì œ

        final_png_bytes = png.tobytes()
        del png
        
        # ğŸš¨ ìµœì¢… ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ë¡œê¹…
        gc.collect() 
        final_memory = process.memory_info().rss / 1024 / 1024
        logger.info(f"[ğŸ§ ] ìš”ì²­ ì™„ë£Œ ë©”ëª¨ë¦¬: {final_memory:.2f} MB (ë³€ë™: {final_memory - initial_memory:.2f} MB)")


        return Response(
            content=final_png_bytes,
            media_type="image/png",
            headers={
                "Access-Control-Allow-Origin": "*",
                "Cache-Control": "no-cache"
            }
        )

    except Exception as e:
        logger.error(f"âŒ ERROR in segmentation processing: {e}", exc_info=True)
        gc.collect()
        return Response(
            content=f"Internal Server Error: {e}".encode(),
            status_code=500
        )


@app.options("/segment_wall_mask")
async def options_segment_wall_mask():
    return Response(
        content=b'',
        status_code=200,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "POST, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )