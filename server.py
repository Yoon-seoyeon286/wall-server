import os
import io
import cv2
import torch
import numpy as np
import gc
import logging
from PIL import Image
from ultralytics import YOLO, SAM
from fastapi import FastAPI, File, UploadFile, Response
from fastapi.middleware.cors import CORSMiddleware

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# ==============================================================================
# ğŸ’¡ [ì¡°ì • ê°€ëŠ¥í•œ ì„¤ì •] - Wall/Object Estimation Parameters (ê°ì²´ ì œì™¸ ì‹¬í™”)
# ==============================================================================
# 1. YOLOv8 ê°ì²´ ê°ì§€ ë¯¼ê°ë„: ë‚®ì¶œìˆ˜ë¡ ë” ë§ì€ ê°ì²´ë¥¼ ê°ì§€í•˜ì—¬ ë²½ ì˜ì—­ì—ì„œ ì œì™¸ (0.10)
YOLO_CONF_THRESHOLD = 0.10 
# 2. ë„ˆë¬´ ì‘ì€ ê°ì²´ ë°•ìŠ¤ í•„í„°ë§ ê¸°ì¤€: ë‚®ì¶œìˆ˜ë¡ ì‘ì€ ê°ì²´ê¹Œì§€ í¬í•¨í•˜ì—¬ ì œì™¸ (0.01)
MIN_BOX_RATIO = 0.01
# 3. ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì‹œ ì‚¬ìš©í•  ëª¨í´ë¡œì§€ ì»¤ë„ í¬ê¸°: í´ìˆ˜ë¡ ì •ì œ íš¨ê³¼ê°€ ê°•í•¨
MORPHOLOGY_KERNEL_SIZE = 9
# 4. ìµœì¢… ë§ˆìŠ¤í¬ ê²½ê³„ì˜ Gaussian Blur í¬ê¸°: í´ìˆ˜ë¡ ê²½ê³„ê°€ ë” ë¶€ë“œëŸ¬ì›€ 
GAUSSIAN_BLUR_SIZE = 13

# ì „ì—­ ë³€ìˆ˜
det_model = None  # YOLOv8n (COCO general detection)
sam_model = None  # MobileSAM
device = "cpu"


@app.on_event("startup")
def load_models_on_startup():
    """ì„œë²„ ì‹œì‘ ì‹œ YOLOv8n + MobileSAM ë¡œë“œ"""
    global det_model, sam_model, device
    
    logger.info("[ğŸ”¥] Starting model loading for YOLOv8n + MobileSAM...")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"[âš™ï¸] Device: {device}")
    
    # Dockerfileì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ëŠ” íŒŒì¼ëª…ê³¼ ì¼ì¹˜
    yolo_checkpoint_path = "yolov8n.pt"  
    sam_checkpoint_path = "mobile_sam.pt"

    try:
        # 1. YOLOv8n ëª¨ë¸ ë¡œë“œ (COCO trained)
        if not os.path.exists(yolo_checkpoint_path):
             logger.error(f"[âŒ] YOLOv8n checkpoint not found at: {yolo_checkpoint_path}")
        else:
            det_model = YOLO(yolo_checkpoint_path)
            det_model.to(device)
            logger.info("[âœ…] YOLOv8n loaded.")
        
        # 2. MobileSAM ë¡œë“œ
        if not os.path.exists(sam_checkpoint_path):
             logger.error(f"[âŒ] MobileSAM checkpoint not found at: {sam_checkpoint_path}")
        else:
            sam_model = SAM(sam_checkpoint_path)
            sam_model.to(device)
            logger.info("[âœ…] MobileSAM loaded.")
        
    except Exception as e:
        logger.error(f"[âŒ] FATAL Model loading failed: {e}", exc_info=True)


def np_from_upload(file_bytes: bytes) -> Image.Image:
    """ë°”ì´íŠ¸ë¥¼ PIL Imageë¡œ ë³€í™˜"""
    return Image.open(io.BytesIO(file_bytes)).convert("RGB")


def filter_small_boxes(boxes, img_shape, min_ratio=MIN_BOX_RATIO):
    """ë„ˆë¬´ ì‘ì€ ë°•ìŠ¤ í•„í„°ë§ (ë…¸ì´ì¦ˆ ì œê±°). ì¡°ì • ê°€ëŠ¥í•œ MIN_BOX_RATIO ì‚¬ìš©"""
    H, W = img_shape
    area_img = H * W
    filtered = []
    for x1, y1, x2, y2 in boxes:
        area = (x2 - x1) * (y2 - y1)
        # ë©´ì ì´ ì „ì²´ ì´ë¯¸ì§€ì˜ min_ratio ë¯¸ë§Œì´ë©´ í•„í„°ë§
        if area / area_img > min_ratio:
            filtered.append([float(x1), float(y1), float(x2), float(y2)])
    return filtered


def post_refine(mask: np.ndarray):
    """ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬: ë…¸ì´ì¦ˆ ì œê±°, í™•ëŒ€, ê°€ì¥ í° ì—°ê²° ì˜ì—­ë§Œ ë‚¨ê¸°ê¸° (ë²½ ì˜ì—­ ì¶”ì •). MORPHOLOGY_KERNEL_SIZE ì‚¬ìš©"""
    mask = mask.astype(np.uint8)
    # ğŸ’¡ ì¡°ì • ê°€ëŠ¥í•œ ì»¤ë„ í¬ê¸° ì ìš©
    kernel = np.ones((MORPHOLOGY_KERNEL_SIZE, MORPHOLOGY_KERNEL_SIZE), np.uint8)

    # ë…¸ì´ì¦ˆ ì œê±° (Opening) + ê²½ê³„ ì±„ìš°ê¸° (Dilate)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    mask = cv2.dilate(mask, kernel, iterations=1)

    # ê°€ì¥ í° ì—°ê²° ì˜ì—­ë§Œ ë‚¨ê¸°ê¸° (ê°€ì¥ í° ì˜ì—­ì„ ì„ íƒí•˜ì—¬ ë²½ ì˜ì—­ì„ ëª…í™•íˆ í•¨)
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        return mask

    largest = max(cnts, key=cv2.contourArea)
    clean = np.zeros_like(mask)
    cv2.drawContours(clean, [largest], -1, 1, thickness=cv2.FILLED)
    
    # ì˜ì—­ì„ ë¶€ë“œëŸ½ê²Œ ë‹«ê¸° (Closing)
    clean = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel, iterations=2)
    return clean


@app.get("/")
async def root():
    return {"status": "ok", "message": "YOLOv8n + MobileSAM Wall Segmentation Server (Tuning Ready)"}


@app.get("/health")
async def health():
    import psutil
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    
    gc.collect()
    
    return {
        "status": "healthy",
        "models_loaded": det_model is not None and sam_model is not None,
        "device": device,
        "memory_mb": round(memory_mb, 2)
    }


@app.post("/segment_wall_mask")
async def segment_wall_mask(file: UploadFile = File(...)):
    """YOLOv8nìœ¼ë¡œ ê°ì²´ ê°ì§€ â†’ MobileSAMìœ¼ë¡œ ë¶„í•  â†’ ê°ì²´ ë§ˆìŠ¤í¬ ë°˜ì „ ë° í›„ì²˜ë¦¬ë¡œ ë²½ ì˜ì—­ ì¶”ì¶œ"""
    
    # ëª¨ë¸ ë¡œë”© ì—¬ë¶€ í™•ì¸
    if det_model is None or sam_model is None:
        logger.error("Segmentation services are unavailable due to model loading failure.")
        return Response(content="Model load failed. Check server startup logs.", status_code=503)

    # ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ìœ„í•´ ë³€ìˆ˜ë“¤ì„ Noneìœ¼ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    img = pil_img = results = boxes = sam_boxes = None 

    try:
        file_bytes = await file.read()
        if not file_bytes:
            return Response(content="File is empty.", status_code=400)
        
        img = np_from_upload(file_bytes)
        original_size = img.size
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ (ë©”ëª¨ë¦¬ ì ˆì•½)
        max_size = 640
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.LANCZOS)

        pil_img = img.copy()
        w, h = pil_img.size
        logger.info(f"[ğŸ“¸] ì´ë¯¸ì§€: {w}x{h}")

        # 1. YOLOv8n ì˜ˆì¸¡ (ê°ì²´ ê°ì§€)
        logger.info("[ğŸ”] YOLOv8n: ê°ì²´ ê°ì§€ ì¤‘...")
        results = det_model.predict(
            pil_img,
            conf=YOLO_CONF_THRESHOLD, 
            imgsz=640,
            device=device,
            verbose=False,
        )[0]

        xyxy = results.boxes.xyxy.cpu().numpy() if results.boxes is not None else []
        boxes = filter_small_boxes(xyxy, pil_img.size[::-1])
        
        logger.info(f"[âœ…] {len(boxes)}ê°œì˜ ìœ íš¨ ê°ì²´ ë°•ìŠ¤ ë°œê²¬")

        # 2. ì˜ˆì™¸ ì²˜ë¦¬: ë°•ìŠ¤ê°€ ì—†ê±°ë‚˜ ë„ˆë¬´ ì‘ìœ¼ë©´, ë²½ì€ ì „ì²´ í™”ë©´ (ë§ˆìŠ¤í¬ 100%)
        if not boxes:
            logger.warning("[âš ï¸] ê°ì²´ ë°•ìŠ¤ê°€ ì—†ì–´ ì „ì²´ ì´ë¯¸ì§€(ë²½) ë°•ìŠ¤ ì‚¬ìš©.")
            mask_img = np.ones((h, w), dtype=np.uint8) * 255
        else:
            # 3. MobileSAM ì˜ˆì¸¡
            logger.info("[ğŸ¨] MobileSAM: ê°ì²´ ë¶„í•  ì¤‘...")
            sam_boxes = boxes
            
            res = sam_model.predict(
                pil_img,
                bboxes=sam_boxes,
                device=device,
                retina_masks=False,
                verbose=False
            )[0]

            if res.masks is None:
                logger.warning("[âš ï¸] MobileSAM ë¶„í•  ì‹¤íŒ¨. ì „ì²´ í™”ë©´ ë°˜í™˜.")
                mask_img = np.ones((h, w), dtype=np.uint8) * 255
            else:
                # 4. ë§ˆìŠ¤í¬ í†µí•© ë° **ë°˜ì „** (ë²½ ì˜ì—­ ì¶”ì¶œ)
                mask_data = res.masks.data.cpu().numpy()
                # ëª¨ë“  ê°ì²´ë“¤ì˜ í†µí•© ë§ˆìŠ¤í¬ (ê°ì²´ = 1, ë°°ê²½ = 0)
                union_objects = (mask_data.sum(axis=0) > 0).astype(np.uint8)
                
                # ğŸ’¡ ê°ì²´ ë§ˆìŠ¤í¬ë¥¼ ë°˜ì „í•˜ì—¬ ë²½(ë°°ê²½) ë§ˆìŠ¤í¬ë¥¼ ì–»ìŠµë‹ˆë‹¤. (í•µì‹¬)
                background_mask = 1 - union_objects
                
                # 5. í›„ì²˜ë¦¬ (ê°€ì¥ í° ë°°ê²½ ì˜ì—­ë§Œ ë‚¨ê¹€)
                refined = post_refine(background_mask) 
                mask_img = (refined * 255).astype(np.uint8)
                
                # 6. ê²½ê³„ë©´ ë¶€ë“œëŸ½ê²Œ ì²˜ë¦¬ (Smoothing)
                mask_img = cv2.GaussianBlur(mask_img, (GAUSSIAN_BLUR_SIZE, GAUSSIAN_BLUR_SIZE), 0)
                
                # ğŸš¨ ë©”ëª¨ë¦¬ ì •ë¦¬ ê°•í™”
                del mask_data, union_objects, background_mask, refined
        
        # 7. ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
        if img.size != original_size:
            mask_img = cv2.resize(
                mask_img, 
                original_size, 
                interpolation=cv2.INTER_LINEAR
            )
        
        # PNG ì¸ì½”ë”©
        _, png = cv2.imencode(".png", mask_img)

        # ğŸš¨ ë©”ëª¨ë¦¬ ì •ë¦¬ ê°•í™” 
        del img, pil_img, results, boxes, sam_boxes
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache() 
        
        gc.collect() 

        final_png_bytes = png.tobytes()
        del png, _
        gc.collect()

        return Response(
            content=final_png_bytes,
            media_type="image/png",
            headers={
                "Access-Control-Allow-Origin": "*",
                "Cache-Control": "no-cache"
            }
        )

    except Exception as e:
        logger.error(f"âŒ ERROR in segmentation processing: {e}", exc_info=True)
        gc.collect()
        return Response(
            content=f"Internal Server Error: {e}".encode(),
            status_code=500
        )


@app.options("/segment_wall_mask")
async def options_segment_wall_mask():
    return Response(
        content=b'',
        status_code=200,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "POST, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )