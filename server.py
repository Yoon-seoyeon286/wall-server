import io
import cv2
import torch
import numpy as np
import gc
from PIL import Image
from ultralytics import YOLO, SAM
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import Response
from fastapi.middleware.cors import CORSMiddleware

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# Lazy loadingì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
det_model = None
sam_model = None
device = "cpu"


def load_models():
    """ëª¨ë¸ì„ ë¡œë“œí•˜ê±°ë‚˜ ì´ë¯¸ ë¡œë“œëœ ê²½ìš° ê±´ë„ˆë›°ë©°, ìë™ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    global det_model, sam_model, device

    if det_model is not None and sam_model is not None:
        return

    print("[ğŸ”¥] Loading heavyweight models (RT-DETR-L + SAM-B)...")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[âš™ï¸] Device set to: {device}")

    try:
        det_model_local = YOLO("rtdetr-l.pt") 
        det_model_local.to(device)

        sam_model_local = SAM("sam_b.pt") 
        sam_model_local.to(device)

        globals()["det_model"] = det_model_local
        globals()["sam_model"] = sam_model_local
        
        print("[âœ”] Models loaded!")
        
    except Exception as e:
        print(f"[âŒ] Model loading failed: {e}")
        globals()["det_model"] = None
        globals()["sam_model"] = None


def np_from_upload(file_bytes: bytes) -> Image.Image:
    """ì—…ë¡œë“œëœ ë°”ì´íŠ¸ë¥¼ PIL Image ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    return Image.open(io.BytesIO(file_bytes)).convert("RGB")


# ğŸ”¥ ë§ˆìŠ¤í¬ ëŒ€í­ í™•ì¥ í•¨ìˆ˜
def expand_mask_massive(mask, iterations=50):
    """ë§ˆìŠ¤í¬ë¥¼ ë§¤ìš° í¬ê²Œ í™•ì¥ì‹œí‚µë‹ˆë‹¤."""
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
    expanded = cv2.dilate(mask, kernel, iterations=iterations)
    
    kernel_large = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
    expanded = cv2.dilate(expanded, kernel_large, iterations=10)
    
    return expanded


# ----------------------------------------------------------------------
# FastAPI ì—”ë“œí¬ì¸íŠ¸
# ----------------------------------------------------------------------

@app.get("/")
async def root():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {"status": "ok", "message": "Wall Segmentation Server (RT-DETR + SAM-B)"}


@app.get("/health")
async def health():
    """ì„œë²„ ìƒíƒœ ë° ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸"""
    import psutil
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    return {
        "status": "healthy",
        "models_loaded": det_model is not None,
        "device": device,
        "memory_mb": round(memory_mb, 2)
    }


@app.post("/segment_wall_mask")
async def segment_wall_mask(file: UploadFile = File(...)):
    """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì—ì„œ ë²½ ë¶„í•  ë§ˆìŠ¤í¬ë¥¼ PNG íŒŒì¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        load_models()

        if det_model is None or sam_model is None:
             return Response(content="Model load failed. Check server logs.", status_code=503)

        file_bytes = await file.read()
        if not file_bytes:
             return Response(content="File is empty.", status_code=400)
             
        img = np_from_upload(file_bytes)

        max_size = 640
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.LANCZOS) 

        pil_img = img.copy()

        # 1. RT-DETR ì˜ˆì¸¡ (ë²½ ê°ì§€)
        results = det_model.predict(
            pil_img,
            conf=0.10,  # ğŸ”¥ ë”ìš± ë‚®ì¶¤ (0.15 â†’ 0.10)
            imgsz=640,
            device=device,
            verbose=False
        )[0]

        xyxy = results.boxes.xyxy.cpu().numpy() if results.boxes is not None else []
        boxes = xyxy.tolist() if xyxy.size > 0 else [] 

        # ë°•ìŠ¤ê°€ ì—†ìœ¼ë©´ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ë°•ìŠ¤ë¡œ
        if not boxes:
            w, h = pil_img.size
            boxes = [[0.0, 0.0, float(w), float(h)]]
            print("[ğŸ”] RT-DETRì´ ë°•ìŠ¤ë¥¼ ì°¾ì§€ ëª»í•´ ì „ì²´ ì´ë¯¸ì§€ ë°•ìŠ¤ë¥¼ ê°•ì œ ì „ë‹¬í•©ë‹ˆë‹¤.")
        else:
            print(f"[ğŸ”] RT-DETRì´ {len(boxes)}ê°œì˜ ë°•ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        # 2. SAM-B ì˜ˆì¸¡ (ë¶„í• )
        res = sam_model.predict(
            pil_img,
            bboxes=boxes,
            device=device,
            retina_masks=False,
            verbose=False
        )[0]

        if res.masks is None:
            print("[âš ï¸] SAMì´ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²´ ì´ë¯¸ì§€ë¥¼ í°ìƒ‰ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            # ğŸ”¥ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨ ì‹œ ì „ì²´ë¥¼ í°ìƒ‰ìœ¼ë¡œ
            h, w = pil_img.size[1], pil_img.size[0]
            refined = np.ones((h, w), dtype=np.uint8)
        else:
            # ë§ˆìŠ¤í¬ í•©ì¹˜ê¸°
            mask = res.masks.data.cpu().numpy()
            union = (mask.sum(axis=0) > 0).astype(np.uint8)
            
            # ğŸ”¥ ë§ˆìŠ¤í¬ ëŒ€í­ í™•ì¥
            refined = expand_mask_massive(union, iterations=80)  # 80ìœ¼ë¡œ ì¦ê°€
        
        wall_pixels = np.sum(refined)
        total_pixels = refined.shape[0] * refined.shape[1]
        coverage_percent = (wall_pixels / total_pixels) * 100
        
        print(f"[ğŸ”] Mask pixels: {wall_pixels} / {total_pixels} ({coverage_percent:.1f}% coverage)")
        
        # ğŸ”¥ í”½ì…€ì´ ë„ˆë¬´ ì ìœ¼ë©´ ì „ì²´ë¥¼ í°ìƒ‰ìœ¼ë¡œ ê°•ì œ ë³€í™˜
        if wall_pixels < 10000:  # 10,000 í”½ì…€ ë¯¸ë§Œì´ë©´
            print(f"[âš ï¸] ë§ˆìŠ¤í¬ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ ({wall_pixels} pixels). ì „ì²´ í™”ë©´ì„ ë§ˆìŠ¤í¬ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            refined = np.ones_like(refined, dtype=np.uint8)
            wall_pixels = np.sum(refined)
            print(f"[âœ”ï¸] ê°•ì œ ì „ì²´ ë§ˆìŠ¤í¬ ìƒì„±: {wall_pixels} pixels")

        # ğŸ”¥ğŸ”¥ğŸ”¥ ë§ˆìŠ¤í¬ë¥¼ 255ë¡œ ë³€í™˜ (ì™„ì „ í°ìƒ‰)
        mask_img = (refined * 255).astype(np.uint8)
        
        # ğŸ”¥ ì¶”ê°€: ë°ê¸° í™•ì¸
        avg_brightness = np.mean(mask_img)
        print(f"[ğŸ”] ë§ˆìŠ¤í¬ í‰ê·  ë°ê¸°: {avg_brightness:.1f} / 255")
        
        _, png = cv2.imencode(".png", mask_img)

        # ë©”ëª¨ë¦¬ ì •ë¦¬ 
        del img, pil_img, results, mask_img, xyxy, boxes, res, file_bytes, refined
        if 'mask' in locals():
            del mask, union
        gc.collect()
        if torch.cuda.is_available():
             torch.cuda.empty_cache()

        return Response(
            content=png.tobytes(),
            media_type="image/png",
            headers={
                "Access-Control-Allow-Origin": "*",
                "Cache-Control": "no-cache"
            }
        )

    except Exception as e:
        print("ğŸ”¥ /segment_wall_mask ERROR:", e)
        import traceback
        traceback.print_exc()
        return Response(
            content=str(e).encode(),
            status_code=500
        )


@app.options("/segment_wall_mask")
async def options_segment_wall_mask():
    """CORS Pre-flight ìš”ì²­ ì²˜ë¦¬"""
    return Response(
        content=b'',
        status_code=200,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "POST, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )