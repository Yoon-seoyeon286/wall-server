import io
import cv2
import torch
import numpy as np
import gc
from PIL import Image
from ultralytics import SAM
from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import Response
from fastapi.middleware.cors import CORSMiddleware

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# ì „ì—­ ë³€ìˆ˜
grounding_dino_processor = None
grounding_dino_model = None
sam_model = None
device = "cpu"


def load_models():
    """Grounding DINO Lite + MobileSAM ë¡œë“œ"""
    global grounding_dino_processor, grounding_dino_model, sam_model, device
    
    if grounding_dino_model is not None and sam_model is not None:
        return
    
    print("[ðŸ”¥] Loading Grounding DINO Lite + MobileSAM...")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[âš™ï¸] Device: {device}")
    
    try:
        # 1. Grounding DINO Lite ë¡œë“œ
        model_id = "IDEA-Research/grounding-dino-tiny"
        processor_local = AutoProcessor.from_pretrained(model_id)
        model_local = AutoModelForZeroShotObjectDetection.from_pretrained(model_id)
        model_local.to(device)
        
        # 2. MobileSAM ë¡œë“œ
        sam_local = SAM("mobile_sam.pt")
        sam_local.to(device)
        
        globals()["grounding_dino_processor"] = processor_local
        globals()["grounding_dino_model"] = model_local
        globals()["sam_model"] = sam_local
        
        print("[âœ…] Models loaded!")
        
    except Exception as e:
        print(f"[âŒ] Model loading failed: {e}")
        globals()["grounding_dino_processor"] = None
        globals()["grounding_dino_model"] = None
        globals()["sam_model"] = None


def np_from_upload(file_bytes: bytes) -> Image.Image:
    """ë°”ì´íŠ¸ë¥¼ PIL Imageë¡œ ë³€í™˜"""
    return Image.open(io.BytesIO(file_bytes)).convert("RGB")


def detect_walls_grounding_dino(image: Image.Image, text_prompt: str = "wall"):
    """Grounding DINOë¡œ ë²½ ê°ì§€"""
    inputs = grounding_dino_processor(
        images=image,
        text=text_prompt,
        return_tensors="pt"
    ).to(device)
    
    with torch.no_grad():
        outputs = grounding_dino_model(**inputs)
    
    # ê²°ê³¼ í›„ì²˜ë¦¬
    results = grounding_dino_processor.post_process_grounded_object_detection(
        outputs,
        inputs.input_ids,
        box_threshold=0.3,  # ë‚®ì€ threshold (ë” ë§Žì´ ê°ì§€)
        text_threshold=0.25,
        target_sizes=[image.size[::-1]]  # (height, width)
    )[0]
    
    boxes = results["boxes"].cpu().numpy()
    scores = results["scores"].cpu().numpy()
    labels = results["labels"]
    
    return boxes, scores, labels


def expand_mask(mask, iterations=20):
    """ë§ˆìŠ¤í¬ í™•ìž¥"""
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))
    return cv2.dilate(mask, kernel, iterations=iterations)


# ----------------------------------------------------------------------
# FastAPI ì—”ë“œí¬ì¸íŠ¸
# ----------------------------------------------------------------------

@app.get("/")
async def root():
    return {"status": "ok", "message": "Grounding DINO Lite + MobileSAM Server"}


@app.get("/health")
async def health():
    import psutil
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    return {
        "status": "healthy",
        "models_loaded": grounding_dino_model is not None and sam_model is not None,
        "device": device,
        "memory_mb": round(memory_mb, 2)
    }


@app.post("/segment_wall_mask")
async def segment_wall_mask(file: UploadFile = File(...)):
    """Grounding DINOë¡œ ë²½ ì°¾ê³  â†’ MobileSAMìœ¼ë¡œ ì •ë°€ ë¶„í• """
    try:
        load_models()
        
        if grounding_dino_model is None or sam_model is None:
            return Response(content="Model load failed.", status_code=503)
        
        file_bytes = await file.read()
        if not file_bytes:
            return Response(content="File is empty.", status_code=400)
        
        img = np_from_upload(file_bytes)
        original_size = img.size
        
        # ë¦¬ì‚¬ì´ì¦ˆ (ì†ë„ í–¥ìƒ)
        max_size = 640
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.LANCZOS)
        
        w, h = img.size
        print(f"[ðŸ“¸] ì´ë¯¸ì§€: {w}x{h}")
        
        # 1ï¸âƒ£ Grounding DINOë¡œ ë²½ ê°ì§€
        print("[ðŸ”] Grounding DINO: ë²½ ê°ì§€ ì¤‘...")
        boxes, scores, labels = detect_walls_grounding_dino(img, text_prompt="wall")
        
        if len(boxes) == 0:
            print("[âš ï¸] ë²½ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì „ì²´ ì´ë¯¸ì§€ë¥¼ ë°•ìŠ¤ë¡œ ì‚¬ìš©.")
            boxes = np.array([[0, 0, w, h]])
        else:
            print(f"[âœ…] {len(boxes)}ê°œì˜ ë²½ í›„ë³´ ë°œê²¬ (confidence: {scores[0]:.2f})")
        
        # 2ï¸âƒ£ MobileSAMìœ¼ë¡œ ì •ë°€ ë¶„í• 
        print("[ðŸŽ¨] MobileSAM: ì •ë°€ ë¶„í•  ì¤‘...")
        
        # ë°•ìŠ¤ í˜•ì‹ ë³€í™˜: [x1, y1, x2, y2] â†’ [[x1, y1, x2, y2]]
        sam_boxes = boxes.tolist()
        
        results = sam_model.predict(
            img,
            bboxes=sam_boxes,
            device=device,
            verbose=False
        )[0]
        
        if results.masks is None or len(results.masks.data) == 0:
            print("[âš ï¸] MobileSAM ì‹¤íŒ¨. ì „ì²´ í™”ë©´ ì‚¬ìš©.")
            mask = np.ones((h, w), dtype=np.uint8)
        else:
            # ëª¨ë“  ë§ˆìŠ¤í¬ í•©ì¹˜ê¸° (ì—¬ëŸ¬ ë²½ì´ ìžˆì„ ìˆ˜ ìžˆìŒ)
            masks = results.masks.data.cpu().numpy()
            mask = (masks.sum(axis=0) > 0).astype(np.uint8)
            
            # í™•ìž¥
            mask = expand_mask(mask, iterations=25)
        
        # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
        if img.size != original_size:
            mask_img = (mask * 255).astype(np.uint8)
            mask_img = cv2.resize(
                mask_img, 
                original_size, 
                interpolation=cv2.INTER_LINEAR
            )
        else:
            mask_img = (mask * 255).astype(np.uint8)
        
        # í†µê³„
        wall_pixels = np.sum(mask_img > 0)
        total_pixels = mask_img.shape[0] * mask_img.shape[1]
        coverage = (wall_pixels / total_pixels) * 100
        
        print(f"[âœ…] Coverage: {coverage:.1f}% ({wall_pixels}/{total_pixels} pixels)")
        
        # ë„ˆë¬´ ìž‘ìœ¼ë©´ ì „ì²´ ì‚¬ìš©
        if coverage < 5.0:
            print(f"[âš ï¸] Coverage ë„ˆë¬´ ë‚®ìŒ. ì „ì²´ í™”ë©´ ì‚¬ìš©.")
            mask_img = np.ones_like(mask_img) * 255
        
        # PNG ì¸ì½”ë”©
        _, png = cv2.imencode(".png", mask_img)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del img, results, mask, mask_img, file_bytes, boxes, scores, labels
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return Response(
            content=png.tobytes(),
            media_type="image/png",
            headers={
                "Access-Control-Allow-Origin": "*",
                "Cache-Control": "no-cache"
            }
        )
    
    except Exception as e:
        print(f"âŒ ERROR: {e}")
        import traceback
        traceback.print_exc()
        return Response(content=str(e).encode(), status_code=500)


@app.options("/segment_wall_mask")
async def options_segment_wall_mask():
    return Response(
        content=b'',
        status_code=200,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "POST, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )