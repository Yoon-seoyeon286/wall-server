import os
import io
import cv2
import torch
import numpy as np
import gc
import logging
from PIL import Image
from ultralytics import SAM # YOLOv8 import ì œê±°
from fastapi import FastAPI, File, UploadFile, Response
from fastapi.middleware.cors import CORSMiddleware

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# ì „ì—­ ë³€ìˆ˜
sam_model = None   # MobileSAM ëª¨ë¸ë§Œ ì‚¬ìš©
device = "cpu"


@app.on_event("startup")
def load_models_on_startup():
    """ì„œë²„ ì‹œì‘ ì‹œ MobileSAMë§Œ ë¡œë“œ"""
    global sam_model, device
    
    logger.info("[ğŸ”¥] Starting model loading for MobileSAM (Standalone Mode)...")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"[âš™ï¸] Device: {device}")
    
    sam_checkpoint_path = "mobile_sam.pt"

    try:
        # 1. MobileSAM ë¡œë“œ
        if not os.path.exists(sam_checkpoint_path):
             logger.error(f"[âŒ] MobileSAM checkpoint not found at: {sam_checkpoint_path}")
        else:
            # SAM ëª¨ë¸ ë¡œë“œ ì‹œ YOLOë¥¼ ì°¸ì¡°í•˜ì§€ ì•Šë„ë¡ SAMë§Œ ë¡œë“œ
            sam_model = SAM(sam_checkpoint_path)
            sam_model.to(device)
            logger.info("[âœ…] MobileSAM loaded.")
        
    except Exception as e:
        logger.error(f"[âŒ] FATAL Model loading failed: {e}", exc_info=True)


def np_from_upload(file_bytes: bytes) -> Image.Image:
    """ë°”ì´íŠ¸ë¥¼ PIL Imageë¡œ ë³€í™˜"""
    return Image.open(io.BytesIO(file_bytes)).convert("RGB")


def expand_mask(mask, iterations=25):
    """ë§ˆìŠ¤í¬ í™•ì¥: ë§ˆìŠ¤í¬ ê²½ê³„ë¥¼ ë¶€ë“œëŸ½ê²Œ ë§Œë“¤ê³  ëˆ„ë½ëœ í‹ˆì„ ë©”ì›ë‹ˆë‹¤."""
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))
    return cv2.dilate(mask, kernel, iterations=iterations)


# ----------------------------------------------------------------------
# FastAPI ì—”ë“œí¬ì¸íŠ¸
# ----------------------------------------------------------------------

@app.get("/")
async def root():
    return {"status": "ok", "message": "MobileSAM Standalone Server"}


@app.get("/health")
async def health():
    import psutil
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    
    gc.collect()
    
    return {
        "status": "healthy",
        "models_loaded": sam_model is not None,
        "device": device,
        "memory_mb": round(memory_mb, 2)
    }


@app.post("/segment_wall_mask")
async def segment_wall_mask(file: UploadFile = File(...)):
    """MobileSAMìœ¼ë¡œ ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•œ ë§ˆìŠ¤í¬ ë¶„í• """
    
    # ëª¨ë¸ ë¡œë”© ì—¬ë¶€ í™•ì¸
    if sam_model is None:
        logger.error("Segmentation services are unavailable due to model loading failure.")
        return Response(content="Model load failed. Check server startup logs.", status_code=503)

    try:
        file_bytes = await file.read()
        if not file_bytes:
            return Response(content="File is empty.", status_code=400)
        
        img = np_from_upload(file_bytes)
        original_size = img.size
        
        # ë¦¬ì‚¬ì´ì¦ˆ (ì†ë„ í–¥ìƒ ë° ì—°ì‚°ëŸ‰ ê°ì†Œ)
        max_size = 480 # <-- ì´ë¯¸ì§€ ìµœëŒ€ í¬ê¸°ë¥¼ 480ìœ¼ë¡œ ì œí•œ
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.LANCZOS)
        
        w, h = img.size
        logger.info(f"[ğŸ“¸] ì´ë¯¸ì§€: {w}x{h}")
        
        # 1ï¸âƒ£ MobileSAM ì…ë ¥ ë°•ìŠ¤: ì´ë¯¸ì§€ ì „ì²´ ì˜ì—­ì„ ì‚¬ìš©
        boxes = np.array([[0, 0, w, h]])
        sam_boxes = boxes.tolist()
        
        logger.info("[ğŸ¨] MobileSAM: ì „ì²´ ì˜ì—­ ë¶„í•  ì¤‘...")
        
        # ultralytics SAM predict (ì „ì²´ ì˜ì—­ ë°•ìŠ¤ ì…ë ¥)
        results = sam_model.predict(
            img,
            bboxes=sam_boxes,
            device=device,
            verbose=False,
            retina_masks=False 
        )[0]
        
        if results.masks is None or len(results.masks.data) == 0:
            logger.warning("[âš ï¸] MobileSAM ì‹¤íŒ¨. ì „ì²´ í™”ë©´ ì‚¬ìš©.")
            mask = np.ones((h, w), dtype=np.uint8)
        else:
            # ëª¨ë“  ë§ˆìŠ¤í¬ í•©ì¹˜ê¸° (ì „ì²´ ì˜ì—­ì„ ë¶„í• í•  ë•Œ SAMì€ ì—¬ëŸ¬ ê°œì˜ ë§ˆìŠ¤í¬ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìŒ)
            masks_tensor = results.masks.data.cpu()
            masks = masks_tensor.numpy()
            
            # ê°€ì¥ í° ë§ˆìŠ¤í¬ë§Œ ì„ íƒí•˜ê±°ë‚˜, ëª¨ë“  ë§ˆìŠ¤í¬ í•©ì¹˜ê¸° (ì—¬ê¸°ì„œëŠ” ëª¨ë“  ë§ˆìŠ¤í¬ í•©ì¹˜ê¸° ìœ ì§€)
            mask = (masks.sum(axis=0) > 0).astype(np.uint8)
            
            # í™•ì¥
            mask = expand_mask(mask)

            # ëª…ì‹œì ìœ¼ë¡œ í…ì„œ ì‚­ì œ (ë©”ëª¨ë¦¬ ì •ë¦¬)
            del masks_tensor, masks
        
        # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
        if img.size != original_size:
            mask_img = (mask * 255).astype(np.uint8)
            mask_img = cv2.resize(
                mask_img, 
                original_size, 
                interpolation=cv2.INTER_LINEAR
            )
        else:
            mask_img = (mask * 255).astype(np.uint8)
        
        # í†µê³„
        wall_pixels = np.sum(mask_img > 0)
        total_pixels = mask_img.shape[0] * mask_img.shape[1]
        coverage = (wall_pixels / total_pixels) * 100
        
        logger.info(f"[âœ…] Coverage: {coverage:.1f}% ({wall_pixels}/{total_pixels} pixels)")
        
        # ë§ˆìŠ¤í¬ ì»¤ë²„ë¦¬ì§€ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì „ì²´ í™”ë©´ì„ ë§ˆìŠ¤í¬ë¡œ ê°„ì£¼
        if coverage < 5.0:
            logger.warning(f"[âš ï¸] Coverage ë„ˆë¬´ ë‚®ìŒ. ì „ì²´ í™”ë©´ ì‚¬ìš©.")
            mask_img = np.ones_like(mask_img) * 255
        
        # PNG ì¸ì½”ë”©
        _, png = cv2.imencode(".png", mask_img)
        
        # ğŸš¨ ë©”ëª¨ë¦¬ ì •ë¦¬ ê°•í™” (í•„ìˆ˜)
        del img, results, mask, mask_img, file_bytes, boxes
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache() 
        
        gc.collect() 
        
        final_png_bytes = png.tobytes()
        del png, _
        gc.collect()

        return Response(
            content=final_png_bytes,
            media_type="image/png",
            headers={
                "Access-Control-Allow-Origin": "*",
                "Cache-Control": "no-cache"
            }
        )
    
    except Exception as e:
        logger.error(f"âŒ ERROR in segmentation processing: {e}", exc_info=True)
        gc.collect()
        return Response(content=f"Internal Server Error: {e}".encode(), status_code=500)


@app.options("/segment_wall_mask")
async def options_segment_wall_mask():
    return Response(
        content=b'',
        status_code=200,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "POST, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )