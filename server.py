import os
import io
import cv2
import torch
import numpy as np
import gc
import logging
from PIL import Image
from ultralytics import YOLO, SAM, __version__ as ultralytics_version
from fastapi import FastAPI, File, UploadFile, Response
from fastapi.middleware.cors import CORSMiddleware
import psutil

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ“Œ ìƒìˆ˜ ì„¤ì •
YOLO_CONF_THRESHOLD = 0.001
MIN_BOX_RATIO = 0.003
MORPHOLOGY_KERNEL_SIZE = 11
GAUSSIAN_BLUR_SIZE = 21
DEPTH_DIFF_THRESHOLD = 8
TOP_BOTTOM_REMOVE_RATIO = 0.15
MAX_IMAGE_SIZE_PIXELS = 640

# ğŸ“Œ ì „ì—­ ëª¨ë¸
det_model = None
sam_model = None
device = "cpu"

# ì‚¬ìš©í•  ëª¨ë¸ íŒŒì¼ ì´ë¦„
YOLO_MODEL_NAME = "yolov8n.pt"
SAM_MODEL_NAME = "mobile_sam.pt"


# â­ ëª¨ë¸ ë¡œë“œ ë° ë‹¤ìš´ë¡œë“œ
@app.on_event("startup")
def load_models_on_startup():
    global det_model, sam_model, device
    logger.info("[ğŸ”¥] Loading Models...")
    # NOTE: ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” GPU(cuda)ë¥¼ ì‚¬ìš©í•´ì•¼ ì„±ëŠ¥ì´ ë‚˜ì˜µë‹ˆë‹¤.
    # device = "cuda" if torch.cuda.is_available() else "cpu"
    device = "cpu" 

    # 1. YOLO ëª¨ë¸ ë¡œë“œ ë° ë‹¤ìš´ë¡œë“œ
    try:
        if not os.path.exists(YOLO_MODEL_NAME):
            logger.info(f"[â¬‡ï¸] {YOLO_MODEL_NAME} íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            det_model = YOLO(YOLO_MODEL_NAME)
            # ë‹¤ìš´ë¡œë“œ í™•ì¸ì„ ìœ„í•œ export (í•„ìˆ˜ ì•„ë‹˜)
            det_model.export(format='torchscript', dynamic=True) 
        else:
            det_model = YOLO(YOLO_MODEL_NAME)
        
        det_model.to(device)
        logger.info(f"[âœ”ï¸] {YOLO_MODEL_NAME} Loaded on {device}")
    except Exception as e:
        logger.error(f"[ğŸ’¥] YOLO Model Load/Download Error: {e}. ê²½ë¡œ ë° ë©”ëª¨ë¦¬ í™•ì¸.")
        det_model = None 

    # 2. SAM ëª¨ë¸ ë¡œë“œ ë° ë‹¤ìš´ë¡œë“œ
    try:
        if not os.path.exists(SAM_MODEL_NAME):
            logger.info(f"[â¬‡ï¸] {SAM_MODEL_NAME} íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            sam_model = SAM(SAM_MODEL_NAME)
        else:
            sam_model = SAM(SAM_MODEL_NAME)

        sam_model.to(device)
        logger.info(f"[âœ”ï¸] {SAM_MODEL_NAME} Loaded on {device}")
    except Exception as e:
        logger.error(f"[ğŸ’¥] SAM Model Load/Download Error: {e}. ê²½ë¡œ ë° ë©”ëª¨ë¦¬ í™•ì¸.")
        sam_model = None 

    if det_model is None or sam_model is None:
        logger.warning("[âš ï¸] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: '/health' ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ìƒíƒœ í™•ì¸ í•„ìš”.")


# ğŸ§° ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì§•
def pil_from_bytes(file_bytes: bytes, mode="RGB") -> Image.Image:
    try:
        img = Image.open(io.BytesIO(file_bytes)).convert(mode)
        w, h = img.size
        
        # ê¹Šì´ ë§µ(Luminance)ì€ ìŠ¤ì¼€ì¼ë§ì„ ê±´ë„ˆë›°ëŠ” ê²ƒì´ ì¢‹ì§€ë§Œ,
        # ì—¬ê¸°ì„œëŠ” í†µì¼ì„±ì„ ìœ„í•´ MAX_IMAGE_SIZE_PIXELSì— ë§ì¶° ë¦¬ì‚¬ì´ì§•í•©ë‹ˆë‹¤.
        if max(w, h) > MAX_IMAGE_SIZE_PIXELS:
            ratio = MAX_IMAGE_SIZE_PIXELS / max(w, h)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.LANCZOS)
            logger.warning(f"[âš ï¸] ì´ë¯¸ì§€ í¬ê¸°ë¥¼ {w}x{h}ì—ì„œ {new_size[0]}x{new_size[1]}ë¡œ ì¶•ì†Œí–ˆìŠµë‹ˆë‹¤.")
            
        return img

    except Exception as e:
        logger.error(f"Image Load Error: {e}")
        return None

# ğŸ§± ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬
def post_refine(mask: np.ndarray):
    mask = mask.astype(np.uint8)
    kernel = np.ones((MORPHOLOGY_KERNEL_SIZE, MORPHOLOGY_KERNEL_SIZE), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
    mask = cv2.dilate(mask, kernel, iterations=1)

    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        return mask

    # ê°€ì¥ í° ì˜ì—­ë§Œ ë‚¨ê¸°ê¸°
    largest = max(cnts, key=cv2.contourArea)
    clean = np.zeros_like(mask)
    cv2.drawContours(clean, [largest], -1, 1, thickness=cv2.FILLED)
    clean = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel, iterations=2)
    return clean


# ğŸª“ ì²œì¥ + ë°”ë‹¥ ì œê±° (AR ìˆ˜ì§ë©´ì„ ê°€ì •)
def remove_top_bottom(mask, ratio=TOP_BOTTOM_REMOVE_RATIO):
    h = mask.shape[0]
    cut = int(h * ratio)
    mask[:cut, :] = 0
    mask[h-cut:, :] = 0
    return mask


# ğŸ§± ìˆ˜ì§ë©´(ë²½)ë§Œ ë‚¨ê¸°ê¸° (ê¹Šì´ ë³€í™”ê°€ ì ì€ ì˜ì—­)
def filter_vertical_surfaces(depth_map, threshold=DEPTH_DIFF_THRESHOLD):
    # ê¹Šì´ ë§µì˜ ê·¸ë˜ë””ì–¸íŠ¸(Sobel) ê³„ì‚°
    depth_map = depth_map.astype(np.float32)
    dx = cv2.Sobel(depth_map, cv2.CV_32F, 1, 0, ksize=3)
    dy = cv2.Sobel(depth_map, cv2.CV_32F, 0, 1, ksize=3)
    magnitude = cv2.magnitude(dx, dy)
    
    # ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸°ê°€ ì„ê³„ê°’ë³´ë‹¤ ì‘ì€ ì˜ì—­ = ê¹Šì´ ë³€í™”ê°€ ì ì–´ ìˆ˜ì§ë©´ì¼ í™•ë¥  ë†’ìŒ
    vertical_strong_mask = (magnitude < threshold).astype(np.uint8) 
    
    return vertical_strong_mask

# ğŸ›‘ ì „ê²½ ê°ì²´ ì œê±° (Sobel ê¸°ë°˜) (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
def create_depth_occlusion_mask(depth_map: np.ndarray, threshold=DEPTH_DIFF_THRESHOLD) -> np.ndarray:
    if depth_map is None:
        return None
    depth_map = depth_map.astype(np.float32)
    grad_x = cv2.Sobel(depth_map, cv2.CV_32F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(depth_map, cv2.CV_32F, 0, 1, ksize=3)
    magnitude = cv2.magnitude(grad_x, grad_y)
    occl = (magnitude > threshold).astype(np.uint8)
    kernel = np.ones((5, 5), np.uint8)
    return cv2.dilate(occl, kernel, iterations=2)


# ğŸšª Wall Mask API
@app.post("/segment_wall_mask")
async def generate_mask(
        image: UploadFile = File(...),
        depth: UploadFile = File(...)
):
    global det_model, sam_model

    if det_model is None or sam_model is None:
        logger.error("Models not loaded.")
        return Response(content="Model load failed. Check server startup logs for file/memory issues.", status_code=503)
    
    # ğŸ“Œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
    img_pil = pil_from_bytes(await image.read())
    depth_bytes = await depth.read()
    depth_pil = pil_from_bytes(depth_bytes, mode="L") # Grayscale (L)ë¡œ ë¡œë“œ
    
    if img_pil is None or depth_pil is None:
        return Response(content="Invalid Image or Depth File.", status_code=400)

    img = np.array(img_pil)
    depth_map = np.array(depth_pil)
    h, w, _ = img.shape
    
    # ğŸ§± YOLO ê°ì§€ (ëª¨ë“  ê°ì²´ bbox)
    logger.info("[ğŸ”] YOLOv8n: ê°ì²´ ê°ì§€ ì¤‘...")
    try:
        det = det_model(img, conf=YOLO_CONF_THRESHOLD, device=device, verbose=False)[0]
        boxes = det.boxes.xyxy.cpu().numpy() if det.boxes is not None else []
    except Exception as e:
        logger.error(f"[ğŸ’¥] YOLO inference failed: {e}")
        boxes = []
        
    del det
    gc.collect()

    if len(boxes) == 0:
        logger.warning("[âš ï¸] ê°ì²´ ë°•ìŠ¤ê°€ ì—†ì–´ ì „ì²´ í™”ë©´(ë²½) ë§ˆìŠ¤í¬ ë°˜í™˜.")
        final_mask = np.ones((h, w), dtype=np.uint8)
    else:
        # ğŸ¯ MobileSAM predict (ëª¨ë“  ê°ì²´ ë¶„í• í•˜ì—¬ í•©ì§‘í•© ê³„ì‚°)
        logger.info(f"[ğŸ¨] MobileSAM: {len(boxes)}ê°œ ê°ì²´ ë¶„í•  ì¤‘...")
        try:
            sam_results = sam_model.predict(img, bboxes=boxes, device=device, verbose=False)[0]

            if sam_results.masks is None or sam_results.masks.data is None:
                logger.warning("[âš ï¸] MobileSAM ë¶„í•  ì‹¤íŒ¨. ì „ì²´ í™”ë©´(ë²½) ë§ˆìŠ¤í¬ ë°˜í™˜.")
                initial_wall_mask = np.ones((h, w), dtype=np.uint8)
            else:
                # ëª¨ë“  ê°ì²´ ë§ˆìŠ¤í¬ì˜ í•©ì§‘í•© (Union) ê³„ì‚°
                mask_data = sam_results.masks.data.cpu().numpy()
                union_objects_mask = (mask_data.sum(axis=0) > 0).astype(np.uint8)
                del mask_data 
                
                # ë²½ ë§ˆìŠ¤í¬ = 1 - ê°ì²´ í•©ì§‘í•© ë§ˆìŠ¤í¬
                initial_wall_mask = 1 - union_objects_mask
            
            del sam_results
            gc.collect()
                
            # ğŸ§¼ í›„ì²˜ë¦¬ (SAM ê²°ê³¼ ì •ì œ ë° ì²œì¥/ë°”ë‹¥ ì œê±°)
            wall_mask_after_sam = post_refine(initial_wall_mask.copy())
            wall_mask_after_sam = remove_top_bottom(wall_mask_after_sam, ratio=TOP_BOTTOM_REMOVE_RATIO)
                
            # ğŸ“Œ ê¹Šì´ ì •ë³´ í™œìš©: ìˆ˜ì§ë©´ í•„í„°ë§
            logger.info("[ğŸ“] ê¹Šì´ ë§µìœ¼ë¡œ ìˆ˜ì§ë©´ í•„í„°ë§ ì¤‘...")
            vertical_mask = filter_vertical_surfaces(depth_map, threshold=DEPTH_DIFF_THRESHOLD)
            
            # 3. SAM ê¸°ë°˜ ë²½ ë§ˆìŠ¤í¬ì™€ ê¹Šì´ ê¸°ë°˜ ìˆ˜ì§ë©´ ë§ˆìŠ¤í¬ì˜ êµì§‘í•©
            final_mask = cv2.bitwise_and(wall_mask_after_sam, vertical_mask)
            
            del initial_wall_mask, wall_mask_after_sam, vertical_mask
            gc.collect()

        except Exception as e:
            logger.error(f"[ğŸ’¥] SAM inference failed: {e}")
            final_mask = np.ones((h, w), dtype=np.uint8)

    # ----------------------------------------------------
    # ğŸ’§ ê²½ê³„ ë¶€ë“œëŸ½ê²Œ (ë¸”ëŸ¬)
    final_mask = cv2.GaussianBlur(final_mask.astype(np.float32), (GAUSSIAN_BLUR_SIZE, GAUSSIAN_BLUR_SIZE), 0)

    # ğŸ PNG ë°˜í™˜ (0-1 float ë§ˆìŠ¤í¬ë¥¼ 0-255 8ë¹„íŠ¸ ì´ë¯¸ì§€ë¡œ ì¸ì½”ë”©)
    _, png = cv2.imencode(".png", (final_mask * 255).astype(np.uint8))
    
    gc.collect()
    
    return Response(png.tobytes(), media_type="image/png")


# ì„œë²„ ìƒíƒœ
@app.get("/")
async def root():
    return {"status": "ok", "message": "Wall Detection Server Ready"}


@app.get("/health")
async def health():
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    gc.collect()
    return {
        "status": "healthy",
        "models_loaded": det_model is not None and sam_model is not None,
        "memory_mb": round(memory_mb, 2)
    }