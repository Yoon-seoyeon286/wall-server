import io
import cv2
import torch
import numpy as np
import gc
from PIL import Image
from ultralytics import SAM
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import Response
from fastapi.middleware.cors import CORSMiddleware

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# ì „ì—­ ë³€ìˆ˜
sam_model = None
device = "cpu"


def load_model():
    """MobileSAM ëª¨ë¸ ë¡œë“œ (ê°€ë³ê³  ë¹ ë¦„)"""
    global sam_model, device
    
    if sam_model is not None:
        return
    
    print("[ğŸ”¥] Loading MobileSAM (lightweight & fast)...")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[âš™ï¸] Device: {device}")
    
    try:
        # ğŸ”¥ MobileSAM ì‚¬ìš© (sam_b.pt ëŒ€ì‹  mobile_sam.pt)
        sam_model_local = SAM("mobile_sam.pt")
        sam_model_local.to(device)
        
        globals()["sam_model"] = sam_model_local
        print("[âœ…] MobileSAM loaded!")
        
    except Exception as e:
        print(f"[âŒ] Model loading failed: {e}")
        globals()["sam_model"] = None


def np_from_upload(file_bytes: bytes) -> Image.Image:
    """ì—…ë¡œë“œëœ ë°”ì´íŠ¸ë¥¼ PIL Imageë¡œ ë³€í™˜"""
    return Image.open(io.BytesIO(file_bytes)).convert("RGB")


def get_center_point(img_shape):
    """ì´ë¯¸ì§€ ì¤‘ì•™ì  ë°˜í™˜ (ë²½ì´ í™”ë©´ ì¤‘ì•™ì— ìˆë‹¤ê³  ê°€ì •)"""
    h, w = img_shape[:2]
    return [[w // 2, h // 2]]


def expand_mask(mask, iterations=20):
    """ë§ˆìŠ¤í¬ í™•ì¥"""
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))
    expanded = cv2.dilate(mask, kernel, iterations=iterations)
    return expanded


# ----------------------------------------------------------------------
# FastAPI ì—”ë“œí¬ì¸íŠ¸
# ----------------------------------------------------------------------

@app.get("/")
async def root():
    return {"status": "ok", "message": "MobileSAM Wall Detection Server"}


@app.get("/health")
async def health():
    import psutil
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    return {
        "status": "healthy",
        "model_loaded": sam_model is not None,
        "device": device,
        "memory_mb": round(memory_mb, 2)
    }


@app.post("/segment_wall_mask")
async def segment_wall_mask(file: UploadFile = File(...)):
    """MobileSAMìœ¼ë¡œ ë²½ ê°ì§€ (ë¹ ë¥´ê³  ì •í™•)"""
    try:
        load_model()
        
        if sam_model is None:
            return Response(content="Model load failed.", status_code=503)
        
        file_bytes = await file.read()
        if not file_bytes:
            return Response(content="File is empty.", status_code=400)
        
        img = np_from_upload(file_bytes)
        
        # ë¦¬ì‚¬ì´ì¦ˆ (ì†ë„ í–¥ìƒ)
        max_size = 640
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = tuple(int(dim * ratio) for dim in img.size)
            img = img.resize(new_size, Image.LANCZOS)
        
        pil_img = img.copy()
        w, h = pil_img.size
        
        print(f"[ğŸ“¸] ì´ë¯¸ì§€ í¬ê¸°: {w}x{h}")
        
        # ğŸ”¥ ì „ëµ 1: ì¤‘ì•™ì  í´ë¦­ (ë²½ì´ í™”ë©´ ì¤‘ì•™ì— ìˆë‹¤ê³  ê°€ì •)
        center_points = get_center_point((h, w))
        
        # MobileSAM ì˜ˆì¸¡ (í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        results = sam_model.predict(
            pil_img,
            points=center_points,
            labels=[1],  # 1 = foreground (ë²½)
            device=device,
            verbose=False
        )[0]
        
        if results.masks is None or len(results.masks.data) == 0:
            print("[âš ï¸] ì¤‘ì•™ì  ê°ì§€ ì‹¤íŒ¨. ì „ì²´ ì´ë¯¸ì§€ ë°•ìŠ¤ ì‚¬ìš©.")
            # ğŸ”¥ ì „ëµ 2: ì „ì²´ ì´ë¯¸ì§€ë¥¼ ë°•ìŠ¤ë¡œ
            results = sam_model.predict(
                pil_img,
                bboxes=[[0, 0, w, h]],
                device=device,
                verbose=False
            )[0]
        
        if results.masks is None:
            print("[âŒ] SAM ê°ì§€ ì™„ì „ ì‹¤íŒ¨. ì „ì²´ í™”ë©´ ë°˜í™˜.")
            mask = np.ones((h, w), dtype=np.uint8)
        else:
            # ë§ˆìŠ¤í¬ ì¶”ì¶œ
            mask_data = results.masks.data.cpu().numpy()
            mask = (mask_data[0] > 0.5).astype(np.uint8)  # ì²« ë²ˆì§¸ ë§ˆìŠ¤í¬ ì‚¬ìš©
            
            # ğŸ”¥ ë§ˆìŠ¤í¬ í™•ì¥ (ì ë‹¹íˆ)
            mask = expand_mask(mask, iterations=25)
        
        # í†µê³„
        wall_pixels = np.sum(mask)
        total_pixels = h * w
        coverage = (wall_pixels / total_pixels) * 100
        
        print(f"[âœ…] Coverage: {coverage:.1f}% ({wall_pixels}/{total_pixels} pixels)")
        
        # ë„ˆë¬´ ì‘ìœ¼ë©´ ì „ì²´ ì‚¬ìš©
        if coverage < 10.0:
            print(f"[âš ï¸] Coverage ë„ˆë¬´ ë‚®ìŒ. ì „ì²´ í™”ë©´ ì‚¬ìš©.")
            mask = np.ones((h, w), dtype=np.uint8)
        
        # PNG ë³€í™˜
        mask_img = (mask * 255).astype(np.uint8)
        _, png = cv2.imencode(".png", mask_img)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del img, pil_img, results, mask, mask_data, mask_img, file_bytes
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return Response(
            content=png.tobytes(),
            media_type="image/png",
            headers={
                "Access-Control-Allow-Origin": "*",
                "Cache-Control": "no-cache"
            }
        )
    
    except Exception as e:
        print(f"âŒ ERROR: {e}")
        import traceback
        traceback.print_exc()
        return Response(content=str(e).encode(), status_code=500)


@app.options("/segment_wall_mask")
async def options_segment_wall_mask():
    return Response(
        content=b'',
        status_code=200,
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "POST, OPTIONS",
            "Access-Control-Allow-Headers": "*"
        }
    )