import os
import io
import cv2
import torch
import numpy as np
import gc
import logging
import math
from PIL import Image
from ultralytics import YOLO, SAM
from fastapi import FastAPI, File, UploadFile, Response
from fastapi.middleware.cors import CORSMiddleware
import psutil # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì ì„ ìœ„í•´ ì¶”ê°€

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==============================================================================
# ğŸ’¡ [ì¡°ì • ê°€ëŠ¥í•œ ì„¤ì •] - Wall/Object Estimation Parameters
# ==============================================================================
# 1. YOLOv8 ê°ì²´ ê°ì§€ ë¯¼ê°ë„
YOLO_CONF_THRESHOLD = 0.001Â 
# 2. ë„ˆë¬´ ì‘ì€ ê°ì²´ ë°•ìŠ¤ í•„í„°ë§ ê¸°ì¤€
MIN_BOX_RATIO = 0.003
# 3. ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬ ì‹œ ì‚¬ìš©í•  ëª¨í´ë¡œì§€ ì»¤ë„ í¬ê¸°
MORPHOLOGY_KERNEL_SIZE = 11
# 4. ìµœì¢… ë§ˆìŠ¤í¬ ê²½ê³„ì˜ Gaussian Blur í¬ê¸°
GAUSSIAN_BLUR_SIZE = 21
# 5. ê¹Šì´ ë§µ ê¸°ë°˜ ê°ì²´ ì œê±° ë¯¼ê°ë„
DEPTH_DIFF_THRESHOLD = 8Â 
# 6. ë©”ëª¨ë¦¬ ë³´í˜¸ë¥¼ ìœ„í•œ ìµœëŒ€ ì´ë¯¸ì§€ í¬ê¸° ì œí•œ
MAX_IMAGE_SIZE_PIXELS = 640Â 
# 7. ì²œì¥ ì˜ì—­ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ì œê±°í•  ìƒë‹¨ ë¹„ìœ¨ (0.0 - 1.0)
CEILING_EXCLUSION_RATIO = 0.15 
# 8. ë°”ë‹¥ ì˜ì—­ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ì œê±°í•  í•˜ë‹¨ ë¹„ìœ¨ (0.0 - 1.0)
FLOOR_EXCLUSION_RATIO = 0.20
# 9. ë¬¸/ì°½ë¬¸ ë“± ì¢ì€ ì˜ì—­ì„ ì œê±°í•  ìµœì†Œ ìˆ˜ì§ ë„ˆë¹„ ë¹„ìœ¨
MIN_WALL_WIDTH_RATIO = 0.40


# ì „ì—­ ë³€ìˆ˜
det_model = NoneÂ  # YOLOv8s
sam_model = NoneÂ  # MobileSAM
device = "cpu"

@app.on_event("startup")
def load_models_on_startup():
Â  Â  """ì„œë²„ ì‹œì‘ ì‹œ YOLOv8s + MobileSAM ë¡œë“œ (MiDaS ì œê±°)"""
Â  Â  global det_model, sam_model, device
Â  Â Â 
Â  Â  logger.info("[ğŸ”¥] Starting model loading for YOLOv8s + MobileSAM (MiDaS Removed)...")
Â  Â Â 
Â  Â  device = "cpu"
Â  Â  logger.info(f"[âš™ï¸] Device: {device}")
Â  Â Â 
Â  Â  yolo_checkpoint_path = "yolov8s.pt"
Â  Â  sam_checkpoint_path = "mobile_sam.pt"

Â  Â  try:
Â  Â  Â  Â  if not os.path.exists(yolo_checkpoint_path):
Â  Â  Â  Â  Â  Â  Â logger.error(f"[âŒ] YOLOv8s checkpoint not found at: {yolo_checkpoint_path}")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  det_model = YOLO(yolo_checkpoint_path)
Â  Â  Â  Â  Â  Â  det_model.to(device)
Â  Â  Â  Â  Â  Â  logger.info("[âœ…] YOLOv8s loaded.")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if not os.path.exists(sam_checkpoint_path):
Â  Â  Â  Â  Â  Â  Â logger.error(f"[âŒ] MobileSAM checkpoint not found at: {sam_checkpoint_path}")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  sam_model = SAM(sam_checkpoint_path)
Â  Â  Â  Â  Â  Â  sam_model.to(device)
Â  Â  Â  Â  Â  Â  logger.info("[âœ…] MobileSAM loaded.")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  logger.info("[âœ…] MiDaS ê¹Šì´ ëª¨ë¸ì€ ë©”ëª¨ë¦¬ ë¬¸ì œë¡œ ì¸í•´ ì œê±°ë˜ì—ˆìœ¼ë©°, Unity ê¹Šì´ ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"[âŒ] FATAL Model loading failed: {e}", exc_info=True)


def np_from_upload(file_bytes: bytes, mode="RGB") -> Image.Image:
Â  Â  """ë°”ì´íŠ¸ë¥¼ PIL Imageë¡œ ë³€í™˜"""
Â  Â  try:
Â  Â  Â  Â  return Image.open(io.BytesIO(file_bytes)).convert(mode)
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"Failed to open image from bytes: {e}")
Â  Â  Â  Â  return None


def filter_small_boxes(boxes, img_shape, min_ratio=MIN_BOX_RATIO):
Â  Â  """ë„ˆë¬´ ì‘ì€ ë°•ìŠ¤ í•„í„°ë§ (ë…¸ì´ì¦ˆ ì œê±°)."""
Â  Â  H, W = img_shape
Â  Â  area_img = H * W
Â  Â  filtered = []
Â  Â  for x1, y1, x2, y2 in boxes:
Â  Â  Â  Â  area = (x2 - x1) * (y2 - y1)
Â  Â  Â  Â  if area / area_img > min_ratio:
Â  Â  Â  Â  Â  Â  filtered.append([float(x1), float(y1), float(x2), float(y2)])
Â  Â  return filtered


def post_refine(mask: np.ndarray):
Â  Â  """ë§ˆìŠ¤í¬ í›„ì²˜ë¦¬: ë…¸ì´ì¦ˆ ì œê±°, í™•ëŒ€, ê°€ì¥ í° ì—°ê²° ì˜ì—­ë§Œ ë‚¨ê¸°ê¸° (ë²½ ì˜ì—­ ì¶”ì •)."""
Â  Â  mask = mask.astype(np.uint8)
Â  Â  kernel = np.ones((MORPHOLOGY_KERNEL_SIZE, MORPHOLOGY_KERNEL_SIZE), np.uint8)

Â  Â  mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
Â  Â  mask = cv2.dilate(mask, kernel, iterations=1)

Â  Â  cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
Â  Â  if not cnts:
Â  Â  Â  Â  return mask

Â  Â  largest = max(cnts, key=cv2.contourArea)
Â  Â  clean = np.zeros_like(mask)
Â  Â  cv2.drawContours(clean, [largest], -1, 1, thickness=cv2.FILLED)
Â  Â Â 
Â  Â  clean = cv2.morphologyEx(clean, cv2.MORPH_CLOSE, kernel, iterations=2)
Â  Â  return clean


def post_filter_vertical_plane(
    mask: np.ndarray, 
    ceiling_ratio: float, 
    floor_ratio: float, 
    min_wall_width_ratio: float
) -> np.ndarray:
    """
    ì²œì¥/ë°”ë‹¥ì„ ì œê±°í•˜ê³  ë²½ ì˜ì—­ë§Œ ë‚¨ê¸°ëŠ” ìˆ˜ì§ í•„í„°ë§ ë° ë³µì› ë¡œì§.
    """
    H, W = mask.shape
    
    # 1. íœ´ë¦¬ìŠ¤í‹± í•„í„°ë§: ì²œì¥ê³¼ ë°”ë‹¥ì„ ê°•ì œë¡œ ì œê±°
    cut_mask = mask.copy()
    ceiling_pixels = int(H * ceiling_ratio)
    floor_pixels = int(H * floor_ratio)
    
    # ìƒë‹¨(ì²œì¥)ê³¼ í•˜ë‹¨(ë°”ë‹¥) ì˜ì—­ì„ 0ìœ¼ë¡œ ì„¤ì •
    if ceiling_pixels > 0:
        cut_mask[:ceiling_pixels, :] = 0
    if floor_pixels > 0:
        cut_mask[H - floor_pixels:, :] = 0
    
    logger.info(f"[âœ‚ï¸] ìƒë‹¨ {ceiling_pixels}px, í•˜ë‹¨ {floor_pixels}px ì œê±° ì™„ë£Œ.")

    # 2. ì œê±° í›„ ë‚¨ì€ ë§ˆìŠ¤í¬ì—ì„œ ê°€ì¥ í° ìˆ˜ì§ ì˜ì—­ë§Œ ì¶”ì¶œ (ë¬¸/ì°½ë¬¸ ì œê±°)
    cnts, _ = cv2.findContours(cut_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not cnts:
        return np.zeros_like(mask)

    # ê°€ì¥ í° ì˜ì—­ ì°¾ê¸°
    largest_cnt = max(cnts, key=cv2.contourArea)
    x, y, w_box, h_box = cv2.boundingRect(largest_cnt)
    
    # ê°€ë¡œ ê¸¸ì´ê°€ ë„ˆë¬´ ì¢ì€ ì˜ì—­(ë¬¸, ì°½ë¬¸ ë“±)ì€ ì œê±°
    if w_box / W < min_wall_width_ratio:
        logger.warning(f"[âš ï¸] ê°€ì¥ í° ì˜ì—­ ë„ˆë¹„ ë¹„ìœ¨ ({w_box/W:.2f})ì´ ë„ˆë¬´ ì‘ì•„ ë²½ìœ¼ë¡œ ì¸ì‹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return np.zeros_like(mask)
    
    # 3. ë²½ ë§ˆìŠ¤í¬ ë³µì›: ì˜ë¦° ìƒí•˜ë‹¨ í”½ì…€ ì±„ìš°ê¸°
    # ë²½ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì›ë˜ ì´ë¯¸ì§€ í¬ê¸°ê¹Œì§€ í™•ì¥í•˜ì—¬ ì±„ì›€
    restored_mask = np.zeros_like(mask)
    
    # ë²½ì˜ ì¢Œìš° ê²½ê³„ë§Œ ìœ ì§€í•˜ê³ , ìƒí•˜ ê²½ê³„ë¥¼ ì›ë˜ ì´ë¯¸ì§€ ìƒë‹¨/í•˜ë‹¨ê¹Œì§€ í™•ì¥
    # y_startëŠ” 0ìœ¼ë¡œ, y_endëŠ” Hë¡œ ì„¤ì •í•˜ì—¬ ë²½ì„ ì´ë¯¸ì§€ ëê¹Œì§€ í™•ì¥
    restored_mask[0:H, x:x + w_box] = 255 
    
    # í™•ì¥ëœ ë§ˆìŠ¤í¬ì— ì›ë˜ì˜ ë§ˆìŠ¤í¬ë¥¼ AND ì—°ì‚°í•˜ì—¬ ë²½ì˜ í˜•íƒœë§Œ ë‚¨ê¹€
    # ì´ ì—°ì‚°ì„ í†µí•´ í™•ì¥ëœ ì§ì‚¬ê°í˜• ì•ˆì—ì„œë§Œ í”½ì…€ì´ ì±„ì›Œì§‘ë‹ˆë‹¤.
    final_wall_mask = cv2.bitwise_and(mask, restored_mask)
    
    del cut_mask, cnts, largest_cnt, restored_mask
    logger.info("[âœ…] ìˆ˜ì§ í•„í„°ë§ ë° ë²½ ì˜ì—­ ë³µì› ì™„ë£Œ.")
    return final_wall_mask


def create_depth_occlusion_mask(depth_map: np.ndarray, threshold=DEPTH_DIFF_THRESHOLD) -> np.ndarray:
Â  Â  """
Â  Â  Unity ê¹Šì´ ì§€ë„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ê²½ ê°ì²´(Occlusion) ë§ˆìŠ¤í¬ ìƒì„±.
Â  Â  """
Â  Â  if depth_map is None:
Â  Â  Â  Â  return None
Â  Â  Â  Â Â 
Â  Â  depth_map = depth_map.astype(np.float32)
Â  Â Â 
Â  Â  # Sobel í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¹Šì´ ë§µì˜ ê²½ê³„(ê¹Šì´ ë³€í™”ê°€ í° ë¶€ë¶„)ë¥¼ ê²€ì¶œ
Â  Â  grad_x = cv2.Sobel(depth_map, cv2.CV_32F, 1, 0, ksize=3)
Â  Â  grad_y = cv2.Sobel(depth_map, cv2.CV_32F, 0, 1, ksize=3)
Â  Â Â 
Â  Â  magnitude = cv2.magnitude(grad_x, grad_y)
Â  Â  del grad_x, grad_yÂ 
Â  Â Â 
Â  Â  occlusion_mask = (magnitude > threshold).astype(np.uint8)
Â  Â  del magnitudeÂ 
Â  Â Â 
Â  Â  kernel = np.ones((5, 5), np.uint8)
Â  Â  occlusion_mask = cv2.dilate(occlusion_mask, kernel, iterations=2)
Â  Â Â 
Â  Â  logger.info(f"[âœ…] Unity ê¹Šì´ ë°ì´í„°ë¡œ ì „ê²½ ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ (Threshold: {threshold}).")
Â  Â  return occlusion_mask


@app.get("/")
async def root():
Â  Â  return {"status": "ok", "message": "YOLOv8s + MobileSAM + Unity Depth Integration Server"}


@app.get("/health")
async def health():
Â  Â  process = psutil.Process()
Â  Â  memory_mb = process.memory_info().rss / 1024 / 1024
Â  Â Â 
Â  Â  gc.collect()
Â  Â Â 
Â  Â  return {
Â  Â  Â  Â  "status": "healthy",
Â  Â  Â  Â  "models_loaded": det_model is not None and sam_model is not None,
Â  Â  Â  Â  "device": device,
Â  Â  Â  Â  "memory_mb": round(memory_mb, 2)
Â  Â  }


@app.post("/segment_wall_mask")
async def segment_wall_mask(
Â  Â  rgb_file: UploadFile = File(..., alias="rgb_file"),
Â  Â  depth_file: UploadFile = File(..., alias="depth_file")
):
Â  Â  """YOLOv8s+SAMìœ¼ë¡œ ê°ì²´ ê°ì§€/ë¶„í•  í›„, Unity ê¹Šì´ ì§€ë„ë¡œ ìµœì¢… ê°€ë ¤ì§ ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•˜ì—¬ ë²½ ì˜ì—­ ì¶”ì¶œ"""
Â  Â Â 
Â  Â  process = psutil.Process()
Â  Â  initial_memory = process.memory_info().rss / 1024 / 1024
Â  Â  logger.info(f"[ğŸ§ ] ìš”ì²­ ì‹œì‘ ë©”ëª¨ë¦¬: {initial_memory:.2f} MB")
Â  Â Â 
Â  Â  if det_model is None or sam_model is None:
Â  Â  Â  Â  logger.error("Segmentation services are unavailable due to model loading failure.")
Â  Â  Â  Â  return Response(content="Model load failed. Check server startup logs.", status_code=503)

Â  Â  pil_img = depth_img_np = depth_occlusion_mask = NoneÂ 

Â  Â  try:
Â  Â  Â  Â  # 1. RGB ì´ë¯¸ì§€ ë¡œë“œ ë° ë©”ëª¨ë¦¬ ë³´í˜¸ë¥¼ ìœ„í•œ í¬ê¸° ì¡°ì •
Â  Â  Â  Â  rgb_bytes = await rgb_file.read()
Â  Â  Â  Â  pil_img = np_from_upload(rgb_bytes, mode="RGB")
Â  Â  Â  Â  del rgb_bytes
Â  Â  Â  Â Â 
Â  Â  Â  Â  if pil_img is None:
Â  Â  Â  Â  Â  Â  logger.error("RGB file could not be loaded.")
Â  Â  Â  Â  Â  Â  return Response(content="Invalid RGB image file.", status_code=400)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  original_size = pil_img.size
Â  Â  Â  Â  w, h = pil_img.size
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ìµœëŒ€ ì´ë¯¸ì§€ í¬ê¸° ì œí•œ ì ìš©
Â  Â  Â  Â  if max(w, h) > MAX_IMAGE_SIZE_PIXELS:
Â  Â  Â  Â  Â  Â  ratio = MAX_IMAGE_SIZE_PIXELS / max(w, h)
Â  Â  Â  Â  Â  Â  new_size = tuple(int(dim * ratio) for dim in pil_img.size)
Â  Â  Â  Â  Â  Â  pil_img = pil_img.resize(new_size, Image.LANCZOS)Â 
Â  Â  Â  Â  Â  Â  w, h = pil_img.size
Â  Â  Â  Â  Â  Â  logger.warning(f"[âš ï¸] ì›ë³¸ ì´ë¯¸ì§€ {original_size[0]}x{original_size[1]}ë¥¼ ë©”ëª¨ë¦¬ ë³´í˜¸ë¥¼ ìœ„í•´ {w}x{h}ë¡œ ì¶•ì†Œí–ˆìŠµë‹ˆë‹¤.")

Â  Â  Â  Â  logger.info(f"[ğŸ“¸] ì²˜ë¦¬ ì´ë¯¸ì§€: {w}x{h}")
Â  Â  Â  Â Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 2. Unity ê¹Šì´ ì§€ë„ ë¡œë“œ ë° ì „ì²˜ë¦¬
Â  Â  Â  Â  depth_bytes = await depth_file.read()
Â  Â  Â  Â Â 
Â  Â  Â  Â  if not depth_bytes or len(depth_bytes) < 100:Â 
Â  Â  Â  Â  Â  Â  logger.warning("[âŒ] í´ë¼ì´ì–¸íŠ¸ ê¹Šì´ íŒŒì¼ì´ ë¹„ì–´ ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 2D AI ë§ˆìŠ¤í¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
Â  Â  Â  Â  Â  Â  depth_img_np = NoneÂ 
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # L (í‘ë°± 8ë¹„íŠ¸) ëŒ€ì‹  16ë¹„íŠ¸ ê¹Šì´ ë°ì´í„°ë„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ëª¨ë“œë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  # í´ë¼ì´ì–¸íŠ¸ê°€ 16ë¹„íŠ¸ í‘ë°± ì´ë¯¸ì§€ë¥¼ ë³´ë‚¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ 'I;16'ì„ ì‹œë„í•©ë‹ˆë‹¤.
Â  Â  Â  Â  Â  Â  Â  Â  depth_img_pil = Image.open(io.BytesIO(depth_bytes))Â 
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # 8ë¹„íŠ¸ë¡œ ë³€í™˜ ë° ë¦¬ì‚¬ì´ì¦ˆ
Â  Â  Â  Â  Â  Â  Â  Â  depth_img_np = np.array(depth_img_pil.convert('L').resize((w, h), Image.NEAREST))
Â  Â  Â  Â  Â  Â  Â  Â  del depth_img_pil
Â  Â  Â  Â  Â  Â  Â  Â  logger.info("[âœ…] í´ë¼ì´ì–¸íŠ¸ ê¹Šì´ ì§€ë„ ë¡œë“œ ë° 8ë¹„íŠ¸ ë³€í™˜ ì™„ë£Œ.")
Â  Â  Â  Â  Â  Â  except Exception as depth_e:
Â  Â  Â  Â  Â  Â  Â  Â  logger.error(f"[âŒ] í´ë¼ì´ì–¸íŠ¸ ê¹Šì´ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {depth_e}")
Â  Â  Â  Â  Â  Â  Â  Â  depth_img_np = None
Â  Â  Â  Â Â 
Â  Â  Â  Â  del depth_bytes


Â  Â  Â  Â  # 3. YOLOv8s + MobileSAMìœ¼ë¡œ ì´ˆê¸° ë²½ ë§ˆìŠ¤í¬ ìƒì„±
Â  Â  Â  Â  # ... (YOLO/SAM ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
Â  Â  Â  Â  logger.info("[ğŸ”] YOLOv8s: ê°ì²´ ê°ì§€ ì¤‘...")
Â  Â  Â  Â  results = det_model.predict(
Â  Â  Â  Â  Â  Â  pil_img, conf=YOLO_CONF_THRESHOLD, imgsz=640, device=device, verbose=False,
Â  Â  Â  Â  )[0]
Â  Â  Â  Â Â 
Â  Â  Â  Â  xyxy = results.boxes.xyxy.cpu().numpy() if results.boxes is not None else []
Â  Â  Â  Â  del resultsÂ 
Â  Â  Â  Â Â 
Â  Â  Â  Â  boxes = filter_small_boxes(xyxy, pil_img.size[::-1])
Â  Â  Â  Â  del xyxy
Â  Â  Â  Â  logger.info(f"[âœ…] {len(boxes)}ê°œì˜ ìœ íš¨ ê°ì²´ ë°•ìŠ¤ ë°œê²¬")

Â  Â  Â  Â  if not boxes:
Â  Â  Â  Â  Â  Â  logger.warning("[âš ï¸] ê°ì²´ ë°•ìŠ¤ê°€ ì—†ì–´ ì „ì²´ ì´ë¯¸ì§€(ë²½) ë°•ìŠ¤ ì‚¬ìš©.")
Â  Â  Â  Â  Â  Â  initial_wall_mask = np.ones((h, w), dtype=np.uint8) * 255
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  logger.info("[ğŸ¨] MobileSAM: ê°ì²´ ë¶„í•  ì¤‘...")
Â  Â  Â  Â  Â  Â  res = sam_model.predict(
Â  Â  Â  Â  Â  Â  Â  Â  pil_img, bboxes=boxes, device=device, retina_masks=False, verbose=False
Â  Â  Â  Â  Â  Â  )[0]
Â  Â  Â  Â  Â  Â  del boxesÂ 
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if res.masks is None:
Â  Â  Â  Â  Â  Â  Â  Â  logger.warning("[âš ï¸] MobileSAM ë¶„í•  ì‹¤íŒ¨. ì „ì²´ í™”ë©´ ë°˜í™˜.")
Â  Â  Â  Â  Â  Â  Â  Â  initial_wall_mask = np.ones((h, w), dtype=np.uint8) * 255
Â  Â  Â  Â  Â  Â  Â  Â  del res
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  mask_data = res.masks.data.cpu().numpy()
Â  Â  Â  Â  Â  Â  Â  Â  del resÂ 
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  union_objects = (mask_data.sum(axis=0) > 0).astype(np.uint8)
Â  Â  Â  Â  Â  Â  Â  Â  del mask_data
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  background_mask = 1 - union_objectsÂ 
Â  Â  Â  Â  Â  Â  Â  Â  del union_objects
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  refined_background = post_refine(background_mask)Â 
Â  Â  Â  Â  Â  Â  Â  Â  del background_mask
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  initial_wall_mask = (refined_background * 255).astype(np.uint8)
Â  Â  Â  Â  Â  Â  Â  Â  del refined_background


Â  Â  Â  Â  # 4. ê¹Šì´ ì§€ë„ë¥¼ ì´ìš©í•œ ìµœì¢… ê°ì²´ ì œì™¸ ë§ˆìŠ¤í‚¹ (Depth Occlusion)
Â  Â  Â  Â  final_mask_img = initial_wall_mask.copy()
Â  Â  Â  Â  del initial_wall_mask
Â  Â  Â  Â Â 
Â  Â  Â  Â  if depth_img_np is not None:
Â  Â  Â  Â  Â  Â  depth_occlusion_mask = create_depth_occlusion_mask(depth_img_np)
Â  Â  Â  Â  Â  Â  del depth_img_npÂ 
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if depth_occlusion_mask is not None:
Â  Â  Â  Â  Â  Â  Â  Â  wall_from_depth = 1 - depth_occlusion_maskÂ 
Â  Â  Â  Â  Â  Â  Â  Â  del depth_occlusion_mask
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  combined_mask = cv2.bitwise_and(final_mask_img, wall_from_depth * 255)
Â  Â  Â  Â  Â  Â  Â  Â  final_mask_img = combined_mask
Â  Â  Â  Â  Â  Â  Â  Â  del wall_from_depth, combined_mask
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  logger.info("[âœ…] Unity í´ë¼ì´ì–¸íŠ¸ ê¹Šì´ ë°ì´í„°ë¡œ ìµœì¢… ê°€ë ¤ì§ ë³´ì • ì™„ë£Œ.")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  logger.warning("[âš ï¸] ê¹Šì´ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨. 2D AI ë§ˆìŠ¤í¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  logger.warning("[âš ï¸] ê¹Šì´ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ 2D AI ë§ˆìŠ¤í¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

Â  Â  Â  Â  # 5. ğŸ’¡ [ë³µêµ¬ëœ ë¡œì§] ì²œì¥/ë°”ë‹¥/ë¬¸ ë¶„ë¦¬ë¥¼ ìœ„í•œ ìˆ˜ì§ í•„í„°ë§ ì ìš©
        final_mask_img = post_filter_vertical_plane(
            final_mask_img,
            CEILING_EXCLUSION_RATIO,
            FLOOR_EXCLUSION_RATIO,
            MIN_WALL_WIDTH_RATIO
        )
        # ë§ˆìŠ¤í¬ë¥¼ 0 ë˜ëŠ” 255 ê°’ìœ¼ë¡œ ì •ê·œí™” (post_filter_vertical_planeì˜ ì¶œë ¥ì´ 0/255ê°€ ì•„ë‹ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
        final_mask_img = (final_mask_img > 0).astype(np.uint8) * 255

Â  Â  Â  Â  # 6. ìµœì¢… ë§ˆìŠ¤í¬ ì •ë¦¬ ë° ì¸ì½”ë”©
Â  Â  Â  Â  final_mask_img = cv2.GaussianBlur(final_mask_img, (GAUSSIAN_BLUR_SIZE, GAUSSIAN_BLUR_SIZE), 0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if pil_img.size != original_size:
Â  Â  Â  Â  Â  Â  final_mask_img = cv2.resize(
Â  Â  Â  Â  Â  Â  Â  Â  final_mask_img,Â 
Â  Â  Â  Â  Â  Â  Â  Â  original_size,Â 
Â  Â  Â  Â  Â  Â  Â  Â  interpolation=cv2.INTER_LINEAR
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  del pil_img
Â  Â  Â  Â Â 
Â  Â  Â  Â  _, png = cv2.imencode(".png", final_mask_img)
Â  Â  Â  Â  del final_mask_img, _Â 

Â  Â  Â  Â  final_png_bytes = png.tobytes()
Â  Â  Â  Â  del png
Â  Â  Â  Â Â 
Â  Â  Â  Â  gc.collect()Â 
Â  Â  Â  Â  final_memory = process.memory_info().rss / 1024 / 1024
Â  Â  Â  Â  logger.info(f"[ğŸ§ ] ìš”ì²­ ì™„ë£Œ ë©”ëª¨ë¦¬: {final_memory:.2f} MB (ë³€ë™: {final_memory - initial_memory:.2f} MB)")


Â  Â  Â  Â  return Response(
Â  Â  Â  Â  Â  Â  content=final_png_bytes,
Â  Â  Â  Â  Â  Â  media_type="image/png",
Â  Â  Â  Â  Â  Â  headers={
Â  Â  Â  Â  Â  Â  Â  Â  "Access-Control-Allow-Origin": "*",
Â  Â  Â  Â  Â  Â  Â  Â  "Cache-Control": "no-cache"
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  )

Â  Â  except Exception as e:
Â  Â  Â  Â  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë©”ëª¨ë¦¬ ìƒíƒœ ë¡œê¹…
Â  Â  Â  Â  error_memory = psutil.Process().memory_info().rss / 1024 / 1024
Â  Â  Â  Â  logger.critical(f"âŒ CRITICAL ERROR (Possible OOM) during segmentation. Current Memory: {error_memory:.2f} MB. Error: {e}", exc_info=True)
Â  Â  Â  Â  gc.collect()
Â  Â  Â  Â  # í´ë¼ì´ì–¸íŠ¸ì—ê²Œ 500 Internal Server Error ë°˜í™˜
Â  Â  Â  Â  return Response(
Â  Â  Â  Â  Â  Â  content=f"Internal Server Error: Segmentation processing failed.".encode(),
Â  Â  Â  Â  Â  Â  status_code=500
Â  Â  Â  Â  )


@app.options("/segment_wall_mask")
async def options_segment_wall_mask():
Â  Â  return Response(
Â  Â  Â  Â  content=b'',
Â  Â  Â  Â  status_code=200,
Â  Â  Â  Â  headers={
Â  Â  Â  Â  Â  Â  "Access-Control-Allow-Origin": "*",
Â  Â  Â  Â  Â  Â  "Access-Control-Allow-Methods": "POST, OPTIONS",
Â  Â  Â  Â  Â  Â  "Access-Control-Allow-Headers": "*"
Â  Â  Â  Â  }
Â  Â  )